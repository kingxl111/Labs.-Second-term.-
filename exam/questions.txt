1. Уровни описания структур данных

При описании какого-либо объекта необходимо чётко различать его абстрактные свойства 
и их конкретную реализацию на данном языке программирования и в данной машине.

ФУНКЦИОНАЛЬНОЙ СПЕЦИФИКАЦИЕЙ какого-либо типа данных называют внешнее формальное определение этого типа данных, 
которое не зависит от языка программирования, а также от конкретной вычислительной машины.
Дать формальное определение типа данных - это значит задать множество значений этого типа и множество изображений этих значений вместе
с правилом их интерпретации, а также базовое множество атрибутов этого типа(это операции и их свойства; функции создания, доступа, модификации)

ПРИМЕР: Функциональная спецификация структурного типа «одномерный массив из пяти элементов вещественного типа, 
пронумерованных от 0 до 4», включает в себя
возможные изображения значений этого структурного типа (пятерки слов), возможные
изображения значений его элементов (последовательность двух групп цифр, разделенных
точкой, со знаком или без знака), интерпретацию любого такого изображения как числа
с фиксированной точкой в позиционной системе счисления с основанием 10, поэлементные
операции и отношения (атрибуты вещественного типа), функцию модификации массива
(модификация любого элемента массива как переменной вещественного типа приводит
к модификации массива).

ЛОГИЧЕСКОЕ ОПИСАНИЕ - это отображение функциональной спецификации на средства выбранного языка программирования.
При выполнении этого отображения могут быть две ситуации: 
1) в выбранном языке программирования есть подходящий тип данных;
2) подходящий тип данных в языке не определен.

В первом случае в программу включают описание объектов имеющегося типа в соответ-
ствии с синтаксическими правилами этого языка.
Во втором случае необходима декомпозиция объекта на такие составные части, которые могут быть описаны как отдельные объекты программы
средствами выбранного языка программирования. При таком подходе следует использовать типы данных, определенные в языке как базовые.

ФИЗИЧЕСКОЕ ПРЕДСТАВЛЕНИЕ - это конкретное отображение на память машины объектов программы в соответствии с логическим описанием.
Такое отображение всегда связано с линеаризацией структур, так как память машины состоит из некоторых единиц(слов или байтов).
Существуют два способа физического представления в памяти машины - сплошное и цепное.

СПЛОШНОЕ ПРЕДСТАВЛЕНИЕ - это представление, при котором объект размещается в памяти в непрерывной последовательности единиц хранения.
Часто применяется для таких структур данных, как массив, очередь, стек, дек.

ЦЕПНОЕ ПРЕДСТАВЛЕНИЕ - это представление, при котором значение объекта разбивается на отдельные части, которые могут быть расположены в разных
участках памяти машины, причем эти участки связаны в цепочку с помощью указателей(т.е. они содержат ссылки на другие части объекта)
---------------------------------------------------------------------------------------------------------------------------------------------------------------------

2. Статические и динамические объекты прогаммы 

В начале программы описываются данные и их тип. Компилятор заранее знает о памяти, которую необходимо предоставить.
Статика - это что-то неменяющееся с течением времени. Переменная - это пример статики. Ее тип неизменен, а значение может меняться.
СТАТИЧЕСКИМИ ОБЪЕКТАМИ называются такие объекты, которые в процессе выполнения программы не меняются. За статику отвечает компилятор.
Вся статика определяется по тексту программы. Тип объекта и область действия объекта - статические свойства объекта.
Однако для решения реальных задач нужна динамика. Конкретное значение переменной - это ее динамическое свойство.

Удобно иметь массивы с длиной, которая обозначается переменной.
Введем понятие RUNTIME - время, когда выполняется программа. То, что нельзя заранее откомпилировать является динамическими характеристиками.
Статические и динамические характеристики называются соответственно характеристиками периода компиляции и периода выполнения программы.

Неограниченный динамизм встречается в машинном языке, в ASM, в интерпретируемых языках. Тут изобилие динамики. 
Левый край - статика - запрет на изменение свойств объекта. Пример неограниченной статики - программа, написанная с использованием лишь констант.

Чем хороша статика? Статические программы очень надежны, так как статические объекты избыточны. Выполнение статических программ происходит очень быстро.
Однако статика не позволяет удалять объект, когда он не нужен. 
А вот динамический объект может создаваться не с начала работы программы и удаляться не в конце работы программы.

Если память выделяется (распределяется) в процессе трансляции и ее объем не меня-
ется от начала до конца выполнения программы, то такой объект является СТАТИЧЕСКИМ.
Если же память выделяется во время выполнения программы и ее объем может меняться,
то такой объект является ДИНАМИЧЕСКИМ.
---------------------------------------------------------------------------------------------------------------------------------------------------------------------

3. Ссылочный тип данных

Принято не ИМЕНОВАТЬ, а ОБОЗНАЧАТЬ динамический объект посредством ссылки на него. Ссылка занимает всего лишь одно машинное слово, что совсем немного.
Мы как бы обманываем компилятор. Для каждого динамического объекта делаем статическую ссылку. Ссылки скалярны.
Например, за ссылкой может скрываться огромная матрица. 

ССЫЛОЧНЫЙ ТИП - это множество значений, которые указывают на объекты целевых(указуемых) типов. Среди ссылочных значений есть nil - not in list (NULL в Си).
Элементами множества ссылочного типа являются конкретные ссылки, указывающие на конкретные объекты, т.е. "адреса" областей памяти
для размещения объектов типа.
Ссылка - это НЕ АДРЕС(хотя внутри скрывается адрес). Компилятор запрещает работать с ссылкой как с адресом.
Транслятор выделяет место для хранения ссылки(шириной в одно машинное слово) в основной памяти. 
Ссылочный тип может быть ИМЕНОВАННЫМ и НЕИМЕНОВАННЫМ. 

Для переменных одного и того же ссылочного типа определены операции присваивания и разыменования, также отношение равенства. 
Операция разыменования обеспечивает доступ к значению обозначаемого ссылкой объекта. Адресация косвенная.

Сначала ссылочная переменная содержит мусор. Ссылочные переменные опасно оставлять неинициализированными! Разыменование нулевого указателя приведет
 к падению всей программы.

В языке динамические объекты порождаются не операторами, а процедурами! 
malloc - динамическое выделение памяти в Си 
Память выделяется(кусочками) не из стека, а из кучи! Создание динамического объекта происходит при вызове определенных процедур, 
фактическим параметром которых является ссылка на элемент данного типа.

Однако ресурсы кучи могут быть забиты, поэтому обработка динамических объектов происходит по следующей схеме:
-порождение динамического объекта
-обработка динамического объекта
-уничтожение динамического объекта

После уничтожения объекта ссылки на него становятся некорректными. Поэтому в современных языках существуют сборщики мусора.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------

4. Файл. Функциональная спецификация

Файл - это структурный регулярный тип, состоящий из компонентов. Структура динамическая. При записи мы его наращиваем. 
Файл размещается на внешней памяти, которая решает вопросы долговременного хранения объектов большого объема. 

Файлы принято именовать. По этому имени его можно найти в долговременной памяти.
Например, файл прямого доступа - это массив на диске.

Файл - это последовательность данных, хранящаяся в долговременной памяти. Порядок хранения - хронологический. Доступна текущая компонента
в текущий момент. Доступ за линейное время. Файл, как лента МТ, потенциально бесконечен.
Файлы могут быть внутренними и внешними.

Функциональная спецификация. 

Компоненты - однотипные.
Значения - это сколь угодно длинные, но конечные последовательности компонент типа Т.

Бесконечное множество значений можно определить с помощью операции конкатенации двух файлов, состоящих из 
компонент одного и того же типа.

Множество атрибутов файлового типа: 
1) Операция конкатенации
2) Операция присваивания. Определяется как покомпонентное копирование одного файла в другой.
3) Отношение равенства
4) Функции: создание, последовательный доступ к каждой компоненте,  модификация, уничтожение.

-----------------------------------------------------------------------------------------------------------------------------------------------------

5. Файл. Логическое описание. Физическое представление.

Файл - это структурный регулярный тип, состоящий из компонентов. Структура динамическая. При записи мы его наращиваем. 
Файл размещается на внешней памяти, которая решает вопросы долговременного хранения объектов большого объема. 

Файлы принято именовать. По этому имени его можно найти в долговременной памяти.
Например, файл прямого доступа - это массив на диске.

Файл - это последовательность данных, хранящаяся в долговременной памяти. Порядок хранения - хронологический. Доступна текущая компонента
в текущий момент. Доступ за линейное время. Файл, как лента МТ, потенциально бесконечен.
Файлы могут быть внутренними и внешними.

Для описания файла в Си необходимо объявить переменную предопределённого
типа FILE∗. Созданный компилятором виртуальный файловый дескриптор может быть
динамически связан с конкретным файлом, потоком или устройством с помощью функций
стандартной библиотеки языка Си.
FILE* <имя объекта-файла>;

Компилятор выделяет память при создании файловой переменной.
Компоненту, которую мы хотим записать в файл, нужно сначала положить в буфер.

Буферная переменная является операбельной частью файла. 

Существует понятие EOF - end of file.

Работа с файлами может быть реализована с помощью процедур fread, fwrite, fseek
Пример: fread(&my_struct, sizeof(elem), elems_quantity, STREAM*) 

----------------------------------------------------------------------------------------------------------------------------------------------

6. Вектор. Функциональная спецификация. Логическое описание и физическое представление.

Вектор является обобщением массивов. Статические массивы удобны - длина известна и можно сразу распределить память. 
Но во многих случаях фиксированная длина не удобна.

Динамические массивы(векторы) располагаются в куче в отличие от статических. Когда динамический массив станет ненужным, мы его сотрем.
То есть это такие массивы, которые можно расширять. Но теперь программист должен вручную распределять память,
что может служить источником ошибок.

Данный массив небезопасен, так как существует риск утечки памяти в случае, когда указатель на массив был утерян, а сам массив никуда не делся.

Функциональная спецификация

Вектор является последовательностью переменной длины. Время доступа к элементам этой последовательности постоянно и не зависит от длины последовательности. 
ОПЕРАЦИИ:
-СОЗДАТЬ
-ПУСТО
-ДЛИНА
-ЗАГРУЗИТЬ
-СОХРАНИТЬ
-ИЗМЕНИТЬ_ДЛИНУ
-РАВЕНСТВО
-УНИЧТОЖИТЬ

Логическое описание:

typedef struct
{
    T* data;
    int size;
} Vector;

void Create(Vector∗ v, int sz)
{
    v−>size = sz;
    v−>data = malloc(sizeof(T) ∗ v−>size));
}

bool Empty(Vector* v)
{
    return v->size == 0;
}

int Size(Vector* v)
{
    return v->size;
}

T Load(Vector* v, int i)
{
    if((i >= 0) && (i < v->size))
        return v->data[i];
}

void Save(Vector* v, int i, T t)
{
    if((i >= 0) && (i < v->size))
        v->data[i] = t;
}

void Resize(Vector* v, int sz)
{
    v->size = sz;
    v->data = realloc(v->data, sizeof(T) * v->size);
}

bool Equal(Vector* l, Vector* r)
{
    if(l->size != r ->size)
        return false;
    for(int i = 0; i < l->size; i++)
        if(l->data[i] != r->data[i])
            return false;
    return true;
}

void Destroy(Vector* v)
{
    v->size = 0;
    free(v->data);
}
------------------------------------------------------------------------------------------------------------------------------------------------

7. Очередь. Функциональная спецификация

Основной принцип очереди: первым пришел - первым вышел. Это стандартное средство сглаживания разницы в быстродействии процессов, 
когда поставщик работает быстрее потребителя. По сути, это лежащая труба(а стоящая труба - это стек).

Очередь - это последовательная динамическая структура с одной читающей головкой и одной записывающей головкой, 
последовательным доступом и неразрушающей записью. 

Для очереди определены следующие операции:
-постановка в очередь нового элемента
-проверка пустоты очереди 
-извлечение из очереди её первого элемента

Первый элемент очереди - буферная переменная. Чтение и запись элемента в очередь осуществляются за О(1).
Подумать, где применяется очередь?

Очередь - это задача поставщик-потребитель

Очереди в компьютере моделируют реальные очереди из жизни. Очереди сообщений, очереди входных/выходных строк unix терминала.
Очередь файлов на распечатку, очереди самолётов, ожидающих посадки, очередь людей, очередь машин, очередь вагонов.
А вот например очереди запросов к программным и аппаратным ресурсам:
запуск/завершение процесса, доступ к регистру, устройству или файлу; являются внутренними задачами информатики.

Функциональная спецификация

Очередь - упорядоченный, одномерный, динамический, изменяемый набор компонент, в котором включение новых компонент
осуществляется с одного конца набора, а всякий доступ к компонентам и их ислючение - на другом конце. 

Чтение элементов - разрушающее! Количество элементов очереди - ее длина. Длина очереди в определении не фиксируется,
значит найти длину стоит O(N). 

Вставить элемент в конец очереди - O(1)
Удалить элемент из очереди - O(1)
Проверка на пустоту - O(1)

Функции очереди:
-СОЗДАТЬ 
-ПУСТО
-В_ОЧЕРЕДЬ
-ИЗ_ОЧЕРЕДИ
-ПЕРВЫЙ
-ДЛИНА
-УНИЧТОЖИТЬ

Постановка в очередь дает очередь! Ввод в очередь - накопительная операция

----------------------------------------------------------------------------------------------------------------------------------------------

8. Очередь. Логическое описание и физическое представление(файл)

Основной принцип очереди: первым пришел - первым вышел. Это стандартное средство сглаживания разницы в быстродействии процессов, 
когда поставщик работает быстрее потребителя. По сути, это лежащая труба(а стоящая труба - это стек).

Очередь - это последовательная динамическая структура с одной читающей головкой и одной записывающей головкой, 
последовательным доступом и неразрушающей записью. 

Для очереди определены следующие операции:
-постановка в очередь нового элемента
-проверка пустоты очереди 
-извлечение из очереди её первого элемента

Первый элемент очереди - буферная переменная. Чтение и запись элемента в очередь осуществляются за О(1).
Подумать, где применяется очередь?

Очередь - это задача поставщик-потребитель

Очереди в компьютере моделируют реальные очереди из жизни. Очереди сообщений, очереди входных/выходных строк unix терминала.
Очередь файлов на распечатку, очереди самолётов, ожидающих посадки, очередь людей, очередь машин, очередь вагонов.
А вот например очереди запросов к программным и аппаратным ресурсам:
запуск/завершение процесса, доступ к регистру, устройству или файлу; являются внутренними задачами информатики.

-----------------------------------------------------------------------------------------------------------------------------------------------

9. Очередь. Логическое описание и физическое представление(массив)

Основной принцип очереди: первым пришел - первым вышел. Это стандартное средство сглаживания разницы в быстродействии процессов, 
когда поставщик работает быстрее потребителя. По сути, это лежащая труба(а стоящая труба - это стек).

Очередь - это последовательная динамическая структура с одной читающей головкой и одной записывающей головкой, 
последовательным доступом и неразрушающей записью. 

Для очереди определены следующие операции:
-постановка в очередь нового элемента
-проверка пустоты очереди 
-извлечение из очереди её первого элемента

Первый элемент очереди - буферная переменная. Чтение и запись элемента в очередь осуществляются за О(1).
Подумать, где применяется очередь?

Очередь - это задача поставщик-потребитель

Очереди в компьютере моделируют реальные очереди из жизни. Очереди сообщений, очереди входных/выходных строк unix терминала.
Очередь файлов на распечатку, очереди самолётов, ожидающих посадки, очередь людей, очередь машин, очередь вагонов.
А вот например очереди запросов к программным и аппаратным ресурсам:
запуск/завершение процесса, доступ к регистру, устройству или файлу; являются внутренними задачами информатики.

При реализации очереди на массиве необходимо зификсировать размер этого массива, ограничив максимальную длину очереди.
3 стратегии реализации: 
1) Трудоголическая очередь. Всегда в начале массива. Хвост данной очереди подвижен. Добавление нового элемента занимает O(1). 
А вот извлечение первого элемента стоит O(N), так как все оставшиеся элементы сдвигаются к началу очереди. 
Применяется: "НИКОГДА!"
2) При "ленивой" стратегии и голова, и хвост подвижны. То есть и извлечение, и добавление элемента в очередь стоит O(1).
Однако данный метод плох, так как требует большого размера исходного массива.
3)Очередь на кольцевом буфере. Склеиваем начало массива с его концом(с помощью операции mod). Операция mod позволяет 
перейти от конца массива к его началу. Данный метод позволяет сделать настоящую очередь, экологически чистую, так как 
не происходит загрязнения от топота ног перемещающихся элементов.
Если переполнится такая очередь, необходимо realloc'ом перевыделить память

const int POOL_SIZE = 100;
typedef struct
{
    int first;
    int size;
    T data[POOL_SIZE];
} queue;

void Create(queue* q)
{
    q->first = 0;
    q->size = 0;
}

bool Empty(const queue* q)
{
    return q->size == 0;
}

int Size(const queue* q)
{
    return q->size;
}

bool Push(queue* q, const T t)
{
    if(q->size == POOL_SIZE)
        return false;
    q->data[(q->first + q->size++) % POOL_SIZE] = t;
    return true;
}

bool Pop(queue* q)
{
    if(!q->size)
        return false;
    q->first++;
    q->first %= POOL_SIZE;
    q->size--;
    return true;
}

T Top(const queue* q)
{
    if(q->size)
        return q->data[q->first];
}

------------------------------------------------------------------------------------------------------------------------------------------------------------

10. Очередь. Логическое описание и физическое представление (динамическиe объекты).

Основной принцип очереди: первым пришел - первым вышел. Это стандартное средство сглаживания разницы в быстродействии процессов, 
когда поставщик работает быстрее потребителя. По сути, это лежащая труба(а стоящая труба - это стек).

Очередь - это последовательная динамическая структура с одной читающей головкой и одной записывающей головкой, 
последовательным доступом и неразрушающей записью. 

Для очереди определены следующие операции:
-постановка в очередь нового элемента
-проверка пустоты очереди 
-извлечение из очереди её первого элемента

Первый элемент очереди - буферная переменная. Чтение и запись элемента в очередь осуществляются за О(1).
Подумать, где применяется очередь?

Очередь - это задача поставщик-потребитель

Очереди в компьютере моделируют реальные очереди из жизни. Очереди сообщений, очереди входных/выходных строк unix терминала.
Очередь файлов на распечатку, очереди самолётов, ожидающих посадки, очередь людей, очередь машин, очередь вагонов.
А вот например очереди запросов к программным и аппаратным ресурсам:
запуск/завершение процесса, доступ к регистру, устройству или файлу; являются внутренними задачами информатики.

Свяжем ссылками одиночные элементы очереди в цепочку в том порядке, в котором
они должны находиться в очереди. Для этого заведем комбинированный тип «элемент
очереди», где наряду с полем данных предусмотрим переменную-ссылку на следующий
элемент того же типа.

struct Item
{
    T data;
    struct Item* next;
};

typedef struct
{
    struct Item* first;
    struct Item* last;
    int size;
} queue;

void Create(queue* q)
{
    q->first = q->last = malloc(sizeof(struct Item));
    q->size = 0;
}

bool Empty(const queue* q)
{
    return q->first == q->last;
}

int Size(const queue* q)
{
    return q->size;
}

bool Push(queue* q, const T t)
{
    if(!(q->last->next = malloc(sizeof(struct Item))));
        return false;
    q->last->next->data = t;
    q->last->next->next = NULL;
    q->last = q->last->next;
    q->size++;
    return true;
}


bool Pop(queue* q)
{
    if(q->first == q->last)
        return false;
    struct Item* pi = q->first;
    q->first = q->first->next;
    q->size--;
    free(pi);
    return true;
}

T Top(const queue* q)
{
    if(q->first != q->last)
        return q->first->data;
}

void Destroy(queue* q)
{
    while(!Empty(q))
    {
        struct Item* pi = q->first;
        q->first = q->first->next;
        free(pi);
    }
    free(q->first);
    q->first = q->last = 0;
    q->size = 0;
}

------------------------------------------------------------------------------------------------------------------------------------------------------

11. Дек. Описание. Примеры задач.

Более pедким ваpиантом очеpеди является дек (Double Ended Queue) — двyхконцовая очеpедь, где чтение и достyп возможны с обоих концов. 
Огpаничив yдаление одним концом, полyчают модель очеpеди с пpиоpитетными льготными элементами. В литературе немного примеров, 
где применяются деки. Это различные железнодорожные разъезды и трамвайные депо и один из методов внешней сортировки. 
Хорошие иллюстрации на тему линейных динамических структур данных (трамвайно-троллейбусного типа). 
Нолучшим примером, конечно,  является сортировочная станция Дейкстры, обеспечивающая преобразование 
выражения в обратную польскую запись с его последующим вычислением.

Операции над деком:
• включение элемента справа;
• включение элемента слева;
• исключение элемента справа;
• исключение элемента слева;
• определение размера;
• очистка.

Задачи, требующие структуры дека, встречаются в вычислительной технике и програм-
мировании гораздо реже, чем задачи, реализуемые на структуре стека или очереди, но
на мероприятии Russian Code Cup 2012 была задача для решения которой требовалось
использовать дек.

---------------------------------------------------------------------------------------------------------------------------------------------------------

12. Стек. Функциональная спецификация

Стек - это структура с единственной читающей-записывающей головкой, последовательным доступом и неразрушающей записью. Чтение из стека
(как и из очереди) разрушающее(это значит, что при считывании элемента из стека он оттуда удаляется). 

Операции:
• Пополнение стека новыми данными
• Проверка стека на пустоту
• Просмотр первого элемента(самого нового элемента)
• Уничтожение последнего добавленного элемента

Примеры стека:
1) Уровни протоколов TCP/IP, а также модель OSI
2) Стопка бумаг
3) Магазин винтовки, автомата

Стеки полезны при решении различных задач информатики:
• Синтаксический анализ текста
• В стеке удобно отводить память под локальные переменные
• Рекурсивные процедуры выполняются, образуя стек вызовов 
• Некоторые ЭВМ, а также калькуляторы имеют стековую архитектуру

Автомат Калашникова превращает стек в очередь! Однако стек имеет неподвижное дно, а у автомата оно плавает.

Функциональная спецификация:
-СОЗДАТЬ
-ПУСТО
-ГЛУБИНА
-В_СТЕК
-ИЗ_СТЕКА
-ВЕРХ
-УНИЧТОЖИТЬ
----------------------------------------------------------------------------------------------------------------------------------------------------------
13. Стек. Логическое описание

Стек - это структура с единственной читающей-записывающей головкой, последовательным доступом и неразрушающей записью. Чтение из стека
(как и из очереди) разрушающее(это значит, что при считывании элемента из стека он отуда удаляется). 

Операции:
• Пополнение стека новыми данными
• Проверка стека на пустоту
• Просмотр первого элемента(самого нового элемента)
• Уничтожение последнего добавленного элемента

Примеры стека:
1) Уровни протоколов TCP/IP, а также модель OSI
2) Стопка бумаг
3) Магазин винтовки, автомата

Стеки полезны при решении различных задач информатики:
• Синтаксический анализ текста
• В стеке удобно отводить память под локальные переменные
• Рекурсивные процедуры выполняются, образуя стек вызовов 
• Некоторые ЭВМ, а также калькуляторы имеют стековую архитектуру

Автомат Калашникова превращает стек в очередь! Однако стек имеет неподвижное дно, а у автомата оно плавает.

Стек является базовым для языка Форт. 
Самый свежий элемент стека называется его верхушкой.
type стек_т  = (ПУСТО | НЕПУСТОЙ_СТЕК)
В языке Форт линейная постфиксная форма записи выражений(1+5->15+).
Для вычисления постфиксных выражений нужно:
1.Встречая операнды помещать на стек
2.Встретили операцию, производим вычисления над двумя вытащенными элементами стека
В языке Форт функции берут аргументы со стека и возвращают результат на стек. Форт выполняет программу – очередь операндов и операций в постфиксном виде.
-----------------------------------------------------------------------------------------------------------------------------------------------------------

14. Стек. Физическое представление(массив)

const int POOL_SIZE = 100;

typedef struct
{
    int size;
    T data[POOL_SIZE];
} stack;

void Create(stack* s)
{
    s->size = 0;
}
bool Empty(stack* s)
{
    return s->size == 0;
}

int Size(stack* s)
{
    return s->size;
}

bool Push(stack* s, T t)
{
    if(s->size >= POOL_SIZE)
        return false;
    s->data[s->size++] = t;
    return true;
}

bool Pop(stack* s)
{
    if(!s->size)
        return false;
    s->size--;
    return true;
}

T Top(stack* s)
{
    if(s->size)
        return s->data[s->size - 1];
}
void Destroy(stack* s)
{
    
}

----------------------------------------------------------------------------------------------------------------------------------------------------------

15. Стек. Физическое представление (динамические объекты).

Теперь опишем реализацию стека на динамических структурах. Для этого понадобится
тип «элемент стека», который содержит ссылку на предыдущую компоненту.

struct Item
{
    T data;
    struct Item* prev;
};

typedef struct
{
    struct Item* top;
    int size;
} stack;

void Create(stack* s)
{
    s->top = 0;
    s->size = 0;
}

bool Empty(stack* s)
{
    return s->top == 0;
}

int Size(stack* s)
{
    return s->size;
}

bool Push(stack* s, T t)
{
    struct Item* i = malloc(sizeof(struct Item));
    if(!i)
        return false;
    i->data = t;
    i->prev = s->top;
    s->top = i;
    s->size++;
    return true;
}

bool Pop(stack* s)
{
    if(!s->size)
        return false;
    struct Item* i = s->top;
    s->top = s->top->prev;
    s->size--;
    free(i);
    return true;
}

T Top(stack* s)
{
    if(s->top)
        return s->top->data;
}

void Destroy(stack* s)
{
    while(s->top)
    {
        struct Item* i = s ->top;
        s->top = s->top->prev;
        free(i);
        s->top = 0;
        s->size = 0;
    }
}

------------------------------------------------------------------------------------------------------------------------------------------------

16. Линейный список. Функциональная спецификация

Линейный список является обобщением ранее изученных последовательных структур с ограниченным доступом: файлов, очередей, стеков.
Линейный список - это конечное упорядоченное динамическое множество элементов типа T. Точнее, это мультимножество.

У списка есть шерсть, по которой можно двигаться. Против шерсти двигаться нельзя. Список может быть закольцован.
Например, это список переменных в описаниях: int x, y, z;
Вставку и удаление можно осуществить из любой части списка. По спискам можно двигаться без удаления или изменения элементов.

Цена поиска элемента в списке - O(N).

В отличие от добавления элемента в массив, добавление элемента в список происходит по настоящему, увеличивая размер списка.
В массиве же размер не меняется, там просто перезаписываются значения.

В списках нет нумерации. Все операции вставки/удаления происходят по значению. Если элемента с таким значением нет, добавляем 
новый элемент в конец. Если есть, то вставка осуществляется на позицию, следующую за найденным элементом.

Удаление/вставка стоят O(N), так как чтобы удалить/вставить, нужно сначала найти этот элемент, что стоит O(N). А сами операции
вставки или удаления работают за постоянное время.

Начало и конец списка могут быть доступны за постоянное время. Будучи более универсальной структурой, список платит 
за произвольное место вставки/удаления временем выполнения этих операций.
Вставка сзади технически проще, если список односвязный и каждый элемент хранит ссылку на следующий.

Функциональная спецификация:

-СОЗДАТЬ
-ПУСТО
-ДЛИНА
-ПЕРВЫЙ
-ПОСЛЕДНИЙ
-СЛЕДУЮЩИЙ
-ПРЕДЫДУЩИЙ
-ВСТАВКА
-УДАЛЕНИЕ
-УНИЧТОЖИТЬ

 Для кольцевых списков верно также:
1. ПРЕДЫДУЩИЙ(ПЕРВЫЙ( l ) ) = ПОСЛЕДНИЙ( l )
2. СЛЕДУЮЩИЙ(ПОСЛЕДНИЙ( l ) ) = ПЕРВЫЙ( l )

--------------------------------------------------------------------------------------------------------------------------------------------------

17. Линейный список. Логическое описание

Линейный список является обобщением ранее изученных последовательных структур с ограниченным доступом: файлов, очередей, стеков.
Линейный список - это конечное упорядоченное динамическое множество элементов типа T. Точнее, это мультимножество.

У списка есть шерсть, по которой можно двигаться. Против шерсти двигаться нельзя. Список может быть закольцован.
Например, это список переменных в описаниях: int x, y, z;
Вставку и удаление можно осуществить из любой части списка. По спискам можно двигаться без удаления или изменения элементов.

Цена поиска элемента в списке - O(N)

В отличие от добавления элемента в массив, добавление элемента в список происходит по настоящему, увеличивая размер списка.
В массиве же размер не меняется, там просто перезаписываются значения.

В списках нет нумерации. Все операции вставки/удаления происходят по значению. Если элемента с таким значением нет, добавляем 
новый элемент в конец. Если есть, то вставка осуществляется на позицию, следующую за найденным элементом.

Удаление/вставка стоят O(N), так как чтобы удалить/вставить, нужно сначала найти этот элемент, что стоит O(N). А сами операции
вставки или удаления работают за постоянное время.

Начало и конец списка могут быть доступны за постоянное время. Будучи более универсальной структурой, список платит 
за произвольное место вставки/удаления временем выполнения этих операций.
Вставка сзади технически проще, если каждый элемент списка хранит ссылку на следующий элемент.

Списковые структуры хорошо реализованы в языках ЛИСП и ПРОЛОГ. В ЛИСПе это основная структура.
На ПРОЛОГЕ список можно записать так: 
.(t1,.(t2,.(t3,.(t4,.(t5, [])))))

Но можно и обычным перечислением:
[t1, t2, t3, t4, t5]
-------------------------------------------------------------------------------------------------------------------------------------------------------------
18. Линейный список. Физическое представление. Итераторы

Список удобно отображать на вектор, пока он не меняется. Сплошное представление удобно, когда список постоянный, неменяющийся.
Однако при удалении элементов в сплошном представлении образуются дырки. Цена вставки/удаления линейная.

Итераторы

Итераторы принято использовать для реализации сложных динамических структур.
То есть нужны абстрактные объекты, которые будут осуществлять переход к следующему элементу, чтобы можно было
читать и перезаписывать элементы. То есть итераторы нужны для навигации.

Итератор начала - это итератор, указывающий на первый элемент, а итератор конца - это итератор, указывающий на фиктивный элемент,
которого в списке нет, на так называемый терминатор.
Благодаря терминатору код выглядит просто.

ОБХОД - это посещение всех элементов данной структуры в определенном порядке ровно один раз. В массиве, например, всё обходится сплошняком.

Например, для обхода массивов в Си используется такая идиома:
int i;
for(i=0;i<len;i++)
{
    // Действия с массивом
}
 
Универсальность идиомы позволит записать обход элементов списка в той же манере:
// Пусть l - некоторый, возможно пустой, список
Iterator i, last = Last(&l); // Элемент после конца
for(i = First(&l); NotEqual(i, last); Next(&i))
{
    // Действия со списком
}

struct Item
{
    struct Item* prev;
    struct Item* next;
    T data;
};

typedef struct
{
    Item* node;
} Iterator;

bool Equal(const Iterator* lhs, const Iterator* rhs)
{
    return lhs->hode == rhs->node;
}

bool NotEqual(const Iterator* lhs, const Iterator* rhs)
{
    return !Equal(lhs, rhs);
}

Iterator Next(Iterator* i)
{
    i->node = i->node->next;
    return i;
}

Iterator Prev(Iterator* i)
{
    i->node = i->node->prev;
    return i;
}

T Fetch(const Iterator* i)
{
    return i->node->data;
}

void Store(const Iterator* i, const T t)
{
    i->node->data = t;
}

Аналогично можно сделать обратные итераторы(итераторы, начинающие обход с конца списка)

--------------------------------------------------------------------------------------------------------------------------------------------------------

19. Линейный список. Физическое представление (массив).

const int POOL_SIZE = 100;
typedef struct
{
    struct Item* head;
    int size;
    struct Item* top;
    struct Item data[POOL_SIZE + 1];
} List;

void Create(List* l)
{
    int i;
    for(i = 0; i < POOL_SIZE; i++)
    {
        l->data[i].next = &(l->data[i + 1]);
    }
    l->data[POOL_SIZE - 1].next = 0;
    l->head = &(l->data[POOL_SIZE]);
    l->head->prev = l->head->next = l->head;
    l->top = &(l->data[0]);
    l->size = 0;
}

Iterator Insert(List* l, Iterator* i, const T t)
{
    Iterator res = { l->top } ;
    if(!res.node)
        return Last(l);
    l->top = l->top->next;
    res.node->data = t;
    res.node->next = i->node;
    res.node->prev = i->node->prev;
    res.node->prev->next = res.node;
    i->node->prev = res.node;
    l->size++;
    return res;
}

Iterator Delete(List* l, Iterator* i)
{
    Iterator res = Last(l);
    if(Equal(i, &res))
        return res;
    res.node = i->node->next;
    res.node->prev = i ->node->prev;
    i->prev->next = res.node;
    l->size--;
    i->node->next = l ->top;
    l->top = i ->node;
    i->node = 0;
    return res;
}

void Destroy(List* l)
{
    l->head = 0;
    l->size = 0;
    l->top = 0;
}

---------------------------------------------------------------------------------------------------------------------------------------------------------

20. Линейный список. Физическое представление (динамические объекты)

Подобно тому, как это было сделано в реализации очереди, соединим начало и конец
списка. Поскольку список двунаправленный, каждый его элемент содержит ровно по две
ссылки: на предыдущий и на последующий элементы списка.Воспользуемся этим, создав фиктивный элемент списка — терминатор. 
Его указатель next будет ссылаться на первый элемент списка (если он есть, в противном случае на терминатор), а prev — на последний
значащий элемент списка (опять-таки, если он есть).

typedef struct
{
    Item* head;
    int size;
} List;

void Create(List* l)
{
    l->head = malloc(sizeof(struct Item));
    l->head->next = l->head->prev = l->head;
    l->size = 0;
}

Iterator First(const List* l)
{
    Iterator res = { l->head->next } ;
    return res;
}

bool Empty(const List* l)
{
    Iterator fst = First(l);
    Iterator lst = Last(l);
    return Equal(&fst, &lst);
}


int Size(const List* l)
{
    return l->size;
}

Iterator Insert(List* l, Iterator* i, const T t)
{
    Iterator res = { malloc(sizeof(struct Item)) } ;
    if(!res.node)
        return Last(l);
    res.node->data = t;
    res.node->next = i->node;
    res.node->prev = i->node->prev;
    res.node->prev->next = res.node;
    i->node->prev = res.node;
    l->size++;
    return res;
}

Iterator Delete(List* l, Iterator* i)
{
    Iterator res = Last(l);
    if(Equal(i, &res))
        return res;
    res.node = i->node->next;
    res.node->prev = i->node->prev;
    i->prev->next = res.node;
    l->size--;
    free(i->node);
    i->node = 0;
    return res;
}

void Destroy(List* l)
{
    struct Item* i = l ->head->next;
    while(i != l ->head)
    {
        struct Item* pi = i;
        i = i->next;
        free(pi);
    }
    free(l->head);
    l->head = 0;
    l->size = 0;
}

-----------------------------------------------------------------------------------------------------------------------------------------------------

21. Списки общего вида

Линейный список общего вида допускает наибольшее число операций:

1) получение доступа к k-й записи списка, чтобы проанализировать или изменить содержимое ее полей;

2) включение новой записи непосредственно перед записью k;

3) исключение записи k из списка;

4) объединение двух или более линейных списков в один;

5) определение числа записей в списке;

6) поиск записи в списке с заданным значением некоторого поля записи;

7) сортировка записей списка в порядке возрастания или убывания значения некоторого поля записи.

-----------------------------------------------------------------------------------------------------------------------------------------------------

22. Деревья. Двоичные деревья

Эта структура данных наилучшим образом приспособлена для решения задач искусственного интеллекта и синтаксического анализа.
То есть транслятор поедает формулы и строит деревья. 

Дерево - иерархическая структура данных, которая есть в жизни. Она состоит из элементов одного типа. Один из элементов - корень.
Дерево предназначено для удобной обработки и хранения элементов. 

Само определение дерева является рекурсивным. У корня есть поддеревья, а у них тоже есть свои поддеревья. 
Дерево, состоящее из одного элемента типа T образует простейшее дерево с одним уровнем. Кроме корня там ничего нет.

Деревья принято рисовать вверх корнем ввиду традиций письменности.
Дерево - это частный случай графа.

/*РИСУЕМ ДВОИЧНОЕ ДЕРЕВО*/ 

Листья - это деревья, у которых нет потомков.
Уровень узла в дереве определяется так: корень имеет уровень 1, а корень каждого поддерева текущего узла имеет уровень, на единицу больше уровня этого узла.
Дерево, у которого k уровней, получается из корня и поддеревьев, хотя бы одно из которых содержит k-1 уровень.
Глубиной дерева называется наибольшее значение уровня вершины.

ДВОИЧНЫЕ ДЕРЕВЬЯ

Это конечное множество узлов, которое либо пусто, либо состоит из корня и двух поддеревьев, называемых левым и правым поддеревьями.
Бинарное дерево - это НЕ ЧАСТНЫЙ СЛУЧАЙ дерева общего вида.

Порядок поддеревьев зафиксирован.

Существенное значение имеет наклон ветвей. Например, деревья общего вида не подчиняются теореме Бойма-Джакопини-Миллса.
Двоичное дерево может выродиться в список. Если это дерево поиска, то такая ситуация крайне нежелательна, ведь заветная сложность O(logN)
превратится в O(N).
--------------------------------------------------------------------------------------------------------------------------------------------------------

23. Двоичное дерево. Функциональная спецификация

Функции:
-СОЗДАТЬ 
-ПОСТРОИТЬ Bt_T x root x Bt_T -> Bt_T
-ПУСТО
-КОРЕНЬ
-СЛЕВА
-СПРАВА
-УНИЧТОЖИТЬ

Свойства
1. ПУСТО(СОЗДАТЬ) = true
2. ПУСТО(ПОСТРОИТЬ(btl , t, btr )) = false
3. КОРЕНЬ(ПОСТРОИТЬ(btl , t, btr )) = t
4. СЛЕВА(ПОСТРОИТЬ(btl , t, btr )) = btl
5. СПРАВА(ПОСТРОИТЬ(btl , t, btr )) = btr
6. ПОСТРОИТЬ(СЛЕВА(bt), КОРЕНЬ(bt), СПРАВА(bt)) = bt

Перечислим некоторые операции над деревьями. Операции заданы в самом общем виде,
без спецификации параметров:
1. чтение данных из узла дерева;
2. создание дерева, состоящего из одного корневого узла;
3. построение дерева из заданных корня и нескольких поддеревьев;
4. присоединение к узлу нового поддерева;
5. замена поддерева на новое поддерево;
6. удаление поддерева;
7. получение узла, следующего за данным в определённом порядке.

------------------------------------------------------------------------------------------------------------------------------------------------------------
24. Двоичное дерево. Логическое описание. Построение и визуализация

В обычных универсальных языках программирования нет такого базового типа данных, как дерево.
Придется его программно моделировать.

Так же, как и в списке, цепная структура дерева будет состоять из динамически порождаемых
элементов, в которых предусмотрены ссылки на очередные компоненты структуры.

struct node
{
    char key;
    struct node* left;
    struct node* right;
}

Ссылки left и right нелинейны, они как бы направлены в разные стороны.
Нелинейность древовидных структур существенно усложняет их обход.

/*ЗДЕСЬ РИСУЕМ ДЕРЕВО, ПРЕДСТАВЛЯЯ ЕГО УЗЛЫ КАК node*/

------------------------------------------------------------------------------------------------------------------------------------------------------------

25. Двоичное дерево. Физическое представление. Прошивка

В представлении бинарного дерева содержатся два указателя — на левое и правое
поддеревья (обозначим их l и r, соответственно). У листьев дерева оба эти указателя
пустые. Поскольку в бинарном дереве, как правило, около половины узлов являются ли-
стьями (если не рассматривать вырожденные случаи), то такое представление оказывается
неэкономичным с точки зрения расхода памяти.
В прошитых бинарных деревьях вместо пустых указателей используются специальные
связи-нити и каждый указатель в узле дерева дополняется однобитовым признаком
ltag и rtag, соответственно. Признак определяет, содержится ли в соответствующем
указателе обычная ссылка на поддерево или в нем содержится связь-нить .
Связь-нить в поле l указывает на узел — предшественник в обратном порядке обхода
(inorder), а связь-нить в поле r указывает на узел — преемник данного узла в прямом
порядке обхода.

Введение признаков ltag и rtag не приводит к сколько-нибудь значительному увели-
чению затрат памяти, зато упрощает алгоритм обхода деревьев, так как для прошитых
деревьев можно выполнить нерекурсивный обход без использования стека.

В настоящее время эта концепция, оставшаяся с тех времен, может быть полезна
для итеративного обхода дерева, например, хранящего элементы множества, с целью
совершения над всеми элементами множества некоторой операции.

Среди прошитых деревьев важный класс составляют правопрошитые деревья, т. е.
прошитые бинарные деревья, у которых используется только правая связь-нить, а в поле
l содержится либо обычный указатель, либо пустой указатель. Поле ltag в таком случае
не используется. На рисунке, приведенном ниже, обычные ссылки нарисованы сплошной
линией, связи-нити — штриховой линией с соответствующих сторон узлов. 
Пустые связи - нити для самого левого и самого правого узлов изображены штриховыми линиями, 
не ведущими ни к какому из узлов дерева. Они символизируют начало и конец обратного
обхода линеаризованного прошивкой дерева.


------------------------------------------------------------------------------------------------------------------------------------------------------------

26. Алгоритмы обхода деревьев

Обходом любой структуры данных является путешествие по всем компонентам структуры в определенном порядке 
ровно один раз. Обход - это что-то линейное, значит, надо как-то линеаризовать дерево.

Способы обхода:
1) КЛП(прямой обход)
    (a)если дерево пусто, то конец обхода
    (b)берется корень 
    (c)выполняется обход левого поддерева
    (d)выполняется обход правого поддерева
2) ЛКП(обратный обход)
    (a)если дерево пусто, то конец обхода
    (b)выполняется обход левого поддерева
    (c)берется корень
    (d)выполняется обход правого поддерева
3) ЛПК(концевой обход)
    (a)если дерево пусто, то конец обхода
    (b)выполняется обход левого поддерева
    (d)выполняется обход правого поддерева
    (c)берется корень

/*ЗДЕСЬ ПИШЕМ КОД*/

------------------------------------------------------------------------------------------------------------------------------------------------------------

27. Особенности представления и обработки деревьев общего вида

Сыновья одного узла - это братья. Вереницу сыновей можно представить через очередь. 

Двоичное дерево можно преобразовать в дерево общего вида.
То есть дерево общего вида можно отобразить следующим образом:
/*ЗДЕСЬ РИСУНОК ДЕРЕВА ОБЩЕГО ВИДА, ПРЕДСТАВЛЕННОГО ЧЕРЕЗ БИНАРНОЕ ДЕРЕВО(У КАЖДОГО УЗЛА ЕСТЬ ССЫЛКА НА РЕБЕНКА И БРАТА */ 
Линейный порядок очереди заменяется каскадным. Старшие братья идут с левой стороны. 

Обход дерева общего вида:
Деревья общего вида имеют более сложную структуру, чем двоичные, и их обход
в силу произвольности числа разветвлений каждого узла не может быть также легко
перенаправлен по двум альтернативам налево и направо. Требуется цикл или рекурсия
по переменному числу разветвлений. Чтобы перебрать всех сыновей, надо просмотреть
до конца их очередь. При этом возможны два приоритета: сначала перебираются братья
(обход в ширину) или сыновья (обход в глубину). Если представлять дерево общего вида
как двоичное, то поиск в глубину аналогичен КЛП-обходу. Для обхода в ширину двоичного
аналога нет.

Особенностью дерева общего вида является то, что при удалении узла, его сыновья тоже удаляются, но братья остаются.
В этом заключается еще одно отличие дерева общего вида от дерева бинарного, где при удалении узла нужно
было серьезно его перестраивать.

1. при поиске в глубину:
(a) если дерево пусто, то конец обхода;
(b) берется корень;
(c) выполняется поиск в глубину для поддерева старшего сына;
(d) выполняется поиск в глубину для следующего брата.
2. при поиске в ширину:
(a) поместить в пустую очередь корень дерева;
(b) если очередь узлов пуста, то конец обхода;
(c) извлечь первый элемент из очереди узлов и поместить в ее конец всех его
сыновей по старшинству;
(d) повторить поиск начиная с п. 2b.

-----------------------------------------------------------------------------------------------------------------------------------------------------------

28. Представление и обработка графов 

Графом называют некоторое подмножество декартова произведения двух множеств. Часто
берутся не разные множества, а одно и то же множество, т. е. граф рассматривается
как подмножество декартова произведения множества на себя. В математическом смысле
граф означает то же, что и отношение. На бумаге (топологически) граф изображается
как множество точек (называемых вершинами ), соединенных линиями (называемыми
ребрами ). Каждая пара вершин соединяется не более чем одним ребром.
Две вершины называются смежными, если в графе есть ребро, соединяющее эти
вершины.

Граф с k вершинами можно представить целочисленным массивом из k столбцов и m
строк, где m — максимальное число вершин, смежных с произвольной вершиной графа.
Элементы столбца матрицы содержат номера смежных вершин. Если у вершины меньше,
чем m ребер, то последние элементы столбца заполняются нулями.

Если граф меняется в процессе обработки, т. е. добавляются и удаляются вершины
и дуги, то удобно использовать списки. Граф описывается с помощью основного списка
вершин и списков дуг. В основной список включены узлы для каждой вершины графа.
С каждым узлом основного списка связан свой список дуг.

ПОИСК В ГЛУБИНУ
Реализация поиска в графе в глубину отличается от поиска в дереве тем, то при всякой
попытке перейти в новую вершину осуществляется проверка, была ли посещена уже эта
вершина. Это связано с тем, что в графе, в отличие от дерева, могут быть циклы и петли,
в силу чего «наивный» алгоритм просто зациклится.

ПОИСК В ШИРИНУ
Поиск в ширину представляет собой прямую реализацию алгоритма поиска кратчайшего
пути из пункта a в пункт b. В курсе дискретной математики данный алгоритм также
известен под назданием "фронт волны".

#include <stdio.h>
#include "sources/List.c"
#include "sources/Queue.c"
#define MAX 5

typedef bool Graph[MAX][MAX];

void breadth_search(Graph G, int init, int goal)
{
    List p; Create_l(&p); Insert(&p, First(&p), init);
    Queue q; Create_q(&q);
    Push(&q, p); /*Пушим текущий Путь в Очередь Путей*/
    while(!Empty(&q))/*Пока в Очереди есть незаконченные пути*/
    {
        p = Front(&q);
        Pop(&q);
        int v = Fetch(First(&p));
        if(v == goal)
        {
            print(First(&p), Last(&p));
        }
        else
        {
            for(inti=0;i<MAX;i++)
        {
        if(G[v][i] && Equal(find(First(&p), Last(&p), i), Last(&p)))
        {
            Insert(&p, First(&p), i);/* Добавляем пункт в Путь */
            Push(&q, p);/* Пушим Путь в конец Очереди*/
            Delete(&p, First(&p));/* Удаляем последний добавленный пункт, т.к . могут быть ещ̈e пункты, в которые можно попасть из данного*/
        }
    }
    int main()
    {
        Graph G={{false, true, true, false, false} ,
        {false , false , false , true, false} ,
        {false, true, false, false, true} ,
        {false, false, true, false, true} ,
        {false, false, false, false, false}} ;/* Задӓeм граф через таблицу смежности*/
        breadth_search(G, 0, 4);
        return 0;
    }
}

------------------------------------------------------------------------------------------------------------------------------------------------

29. Деревья выражений

Выражения нелинейны и рекурсивны так же, как и деревья. Выражения бывают:
-арифметические
-логические
-информатические

Какие существуют формы записи выражений?
-префиксная(КЛП)
-инфиксная(ЛКП)
-постфиксная(ЛПК)

Постфиксная форма самая конструктивная для стекированных архитектур. Она позволяет нерекурсивно, не возвращаясь, обрабатывать выражения.
Выражение представляет собой сумму нескольких терм.

/*ЗДЕСЬ РИСУЕМ ДЕРЕВО КАКОГО-НИБУДЬ АРИФМЕТИЧЕСКОГО ВЫРАЖЕНИЯ*/

Не забыть рассказать, что существуют 3 алгоритма обработки выражений, про то, как они
связаны с деревьями выражений.

-------------------------------------------------------------------------------------------------------------------------------------------------------

30. Алгоритм Рутисхаузера(1951)

"Танцевальная процессия вокруг скобочных скал"

Один из наиболее ранних алгоритмов. Данный алгоритм требует от выражения полной скобочной структуры. 
D = ((C-(B*L))+K)
Неявное старшинство операций при этом не учитывается.

Алгоритм присваивает каждому символу-лексеме исходного выражения-номер уровня по следующему правилу:
-если лексема - открывающая скобка или переменная, то значение уровня увеличивается на 1
-если лексема - закрывающая скобка или знак операции, то значение уровня уменьшается на 1

Для выражения ( А + ( В - С ) ) 
              1 2 1 2 3 2 3 2 1

Расставили уровни

Основные этапы алгоритма Рутисхаузера:
1)Расставить уровни
2)Отыскать элементы строки с максимальным значением уровня
3)Выделить тройку - два операнда с максимальным значением уровня и операцию, которая заключена между ними
4)Результат выполненной операции обозначить вспомогательной переменной
5)Из исходного выражения удалить выделенную тройку вместе со скобками, а на ее место поставить 
новую перменную, обозначающую результат, со значением уровня, на единицу меньшим, чем у выделенной тройки.
6)Выполнять пункт 5 до тех пор, пока в строке не останется один операнд - результат всего выражения.

( ( ( ( А + В ) * С ) / D ) - E )
1 2 3 4 5 4 5 4 3 4 3 2 3 2 1 2 1

( ( ( R * С ) / D ) - E )
1 2 3 4 3 4 3 2 3 2 1 2 1

( ( K / D ) - E )
1 2 3 2 3 2 1 2 1

( M - E )
1 2 1 2 1

Q
1

---------------------------------------------------------------------------------------------------------------------------------------------------------

31. Алгоритм Бауэра и Замельзона

Ранний стековый метод.

Используются два стека и таблица функций перехода. Один стек (T) используется при
трансляции выражения, а второй (E) – во время интерпретации выражения.
В таблице переходов задаются функции, которые должен выполнить транслятор при
разборе выражения:

• f1: заслать операцию из входной строки в стек Т; читать следующий символ стpоки;
• f2: выделить тройку – взять операцию с вершины стека Т и два операнда с вершины
стека Е; вспомогательную переменную – результат операции занести в стек Е; заслать
операцию из входной строки в стек Т; читать следующую лексему стpоки;
• f3: исключить лексему из стека Т; читать следующий символ стpоки;
• f4: выделить тройку – взять операцию с вершины стека Т и два операнда с вершины
стека Е; вспомогательную переменную – результат операции, занести в стек Е; по
таблице определить функцию для данной лексемы входной строки;
• f5: выдача сообщения об ошибке;
• f6: завершение работы.
Таблица переходов для алгебраических выражений будет иметь вид (знак $ является
признаком пустого стека или пустой строки):
----------------------------------------------
              $ ( + - * / ) - текущая операция
----------------------------------------------
Операция| $ | 6 1 1 1 1 1 5
  на    | ( | 5 1 1 1 1 1 3
вершине | + | 4 1 2 2 1 1 4
стека   | - | 4 1 2 2 1 1 4
  T     | * | 4 1 4 4 2 2 4
        | / | 4 1 4 4 2 2 4
----------------------------------------------

Выражение просматривается слева направо и над каждой лексемой выполняются
следующие действия: если очередная лексема входной строки является операндом, то она
безусловно переносится в стек Е; если это операция, то по таблице функций перехода
определяется номер функции для выполнения.

------------------------------------------------------------------------------------------------------------------------------------------------------

32. Алгоритм Дейкстры(Dijkstra's sort station)

Алгоритм сортировочной станции Дейкстры — способ разбора математических
выражений, представленных в обычной инфиксной нотации.

Результат – в виде обратной польской записи или в виде дерева выражения.

Алгоритм можно условно разделить на три этапа:
1)Считывание выражения
2)Преобразование выражения из инфиксной в постфиксную запись
3)Построение дерева выражения

Так же, как и при вычислении значений выражений в обратной
польской записи, алгоритм работает при помощи стека. Для преобразования в обратную
польскую нотацию используется 2 очереди: входная и выходная, и стек для хранения
операций, еще не добавленных в выходную очередь. При преобразовании выражения
считывается лексема и производятся действия, зависящие от её конкретного вида, пока не все синтаксические символы (лексемы) будут обработаны.

Сам алгоритм:
Если считанная лексема является константой или переменной:
    перекладываем ее в выходную очередь.
Если считанная лексема является открывабщей скобкой:
    кладем ее на стек.
Если считанная лексема является закрывающей скобкой:
    необходимо доставать элементы из стека и перекладывать их в выходную очередь до тех пор, пока не встретим в стеке открывающую скобку. 
    Открывающую и закрывающую скобки в выходную очередь добавлять не надо.
Если считанная лексема является операцией:
    вынимаем из стека все операции, которые должны выполниться раньше данной, и перемещаем их в выходную очередь, а данную операцию кладем на стек.

Построение дерева выражения из обратной польской записи:
Для данного алгоритма также потребуется стек, только теперь в нём будут не операции, а операнды.
Если считанная лексема является операндом:
    кладём её на стек.
Если считанная лексема является операцией:
    если операция левоассоциативная:
        вынимаем из стека два операнда, выполняем операцию и заносим результат обратно в стек
        Под выполнением операции следует понимать построение дерева, у которого корнем будет данная операция,
        левым поддеревом - второй элемент, выложенный из стека, а правым поддеревом - первый элемент, выложенный из стека
    если операция правоассоциативная:
        вынимаем из стека один операнд, выполняем операцию и заносим результат обратно в стек
        Под выполнением операции следует понимать построение дерева, у которого корнем будет данная операция,
        левым(или правым) поддеревом - элемент, выложенный из стека.

Чтобы восстановить исходное выражение по его дереву, необходимо осуществить ЛКП обход.

Сложность алгоритма Дейкстры составляет O(N), так как каждая операция будет добавлена в стек и удалена из стека ровно один раз.

-----------------------------------------------------------------------------------------------------------------------------------------------------------

33. Деревья поиска

Двоичные деревья хороши для того, чтобы представить множество данных, которыми можно оперировать по ключу.
Например, таблица - структура с множеством данных, которыми можно оперировать по ключу.

Если дерево организовать так, что для каждой вершины t справедливо утверждение, что все ключи левого поддерева меньше ключа t,
а все ключи правого поддерева больше ключа t, то такое дерево будет называться деревом поиска.

Неупорядоченная таблица проигрывает дереву по всем параметрам.
Даже упорядоченная таблица проигрывает дереву, так как вставка и удалаение происходит за O(N).

В дереве поиска можно легко найти элемент с заданным ключом. Сложность поиска - всего O(logN).
Если искомого элемента нет, ответ выдается в виде пустой ссылки.
По построению дерева поиска, переходя к одному из поддеревьев, мы автоматически исключаем из рассмотрения
другое поддерево, содержащее половину узлов. При дальнейшем рассмотрении исключа-
ется половина половины и т. д. 

p* locate(int x, p* t)
{
    while(t != NULL && t->key != x)
    {
        if (t->key < x)
        {
            t = t->r;
        }
        else
        {
            t = t->l;
        }
    }
    return t;
}


Вообще, терминатор упрощает код, воспользуемся им:

p* locate(int x, p* t)
{
    s->key = x;// барьерное значение заносится в барьерный элемент
    while(t->key != x)// условие упрощено
    {
        if (t->key < x)
        {
            t = t->r;
        }
        else
        {
            t = t->l;
        }
    }
    return t;
}

Получился некий гамак. Однако теперь усложнилась вставка и удаление, так как нужно этот гамак учитывать.
Благодаря барьерному элементу скорость поиска увеличивается.

Поиск с включениями отличается от обычного поиска тем, что в случае, когда искомый элемент не найден,
он добавляется на то место, где теоретически должен был находиться. 

struct word{
    int key;
    int count ;
    struct word∗ l;
    struct word∗ r;
};
typedef struct word∗ wp;

void search(int x, wp∗ p)
{
    if (∗p == NULL) // слова в дереве нет , включение
    {
        ∗p = (wp)malloc(sizeof(struct word));
        (∗p)−>key = x ;
        (∗p)−>count = 1;
        (∗p)−>l = NULL;
        (∗p)−>r = NULL;
    } // продолжение поиска
    else if (x < (∗p)−>key)
    {
        search(x, &(∗p)−>l);
    }
    else if (x > (∗p)−>key)
    {    
        search(x, &(∗p)−>r);
    }
    else
    { // поиск окончен , фиксация еще одного вхождения искомого слова
        (∗p)−>count++;
    }
}

То есть сначала search() делает то же самое, что и locate() - осуществляет поиск в дереве.
-------------------------------------------------------------------------------------------------------------------------------------------------

34. Сбалансированные деревья поиска.

Дерево поиска - быстрая структура, однако оно может выродиться. Желательно не нарушать баланс дерева.
Поскольку каждое включение элемента приводит к разбалансировке дерева поиска, надо придумать оперативную балансировку 
just in time при вставке нового элемента. 

СБАЛАНСИРОВАННЫМ ДЕРЕВОМ было названо такое дерево, высоты поддеревьев каждой из вершин которого отличаются не более чем на единицу.
Высота всегда должна быть O(logN).

В честь авторов такие деревья называются AVL-деревьями(Адельсон-Вельский-Ландис)

В сбалансированных деревьях за время, пропорциональное O(logN), даже в худшем
случае, можно выполнить следующие операции:
• найти вершину с данным ключом;
• включить новую вершину с заданным ключом;
• исключить вершину с указанным ключом.

Идеально сбалансированные деревья также являются AVL-деревьями.
Это определение приводит к простой процедуре ребалансировки дерева, причём средняя
длина пути поиска практически совпадает с его длиной в идеально сбалансированном
дереве.

По теореме Адельсона-Вельского–Ландиса сбалансированное дерево никогда не будет
по высоте превышать идеально сбалансированное более чем на 45%, независимо от
количества вершин.

Поскольку принцип их построения очень напоминает определение чисел Фибоначчи, то
мы будем называть такие деревья деревьями Фибоначчи. Их определение более, чем
стандартно:
1. Пустое дерево есть дерево Фибоначчи высоты 0.
2. Единственная вершина есть дерево Фибоначчи высоты 1.
3. Если T_h−1 и T_h−2 — деревья Фибоначчи высотой h − 1 и h − 2, 
то T_h = (T_h−1, x, T_h−2) также дерево Фибоначчи высотой h.
4. Никакие другие деревья деревьями Фибоначчи не являются.

---------------------------------------------------------------------------------------------------------------------------------------------

35. Сбалансированные деревья поиска. Вставка

Проанализируем операцию включения в сбалансированное дерево новой вершины. Мы
надеемся, что цена этой операции не ухудшит замечательные свойства AVL-деревьев. Если
наше дерево состоит из корня t и левого и правого поддеревьев L и R соответственно, то
либо оно идеально сбалансировано и вставка новой вершины углубит одно из поддеревьев
на единицу. 
Либо вставляемая вершина попадет в более низкое поддерево и улучшит
сбалансированность. 
Наконец, при попадании нового узла в более высокое поддерево, 
AVL - сбалансированность дерева нарушится и возникнет необходимость балансировки дерева.

/*ЗДЕСЬ НУЖЕН РИСУНОК ТОЛЬКО ЧТО РАЗБАЛАНСИРОВАВШЕГОСЯ AVL-ДЕРЕВА(с крестиками там, где вершин быть не должно!)*/

Процесс балансировки заключается в вертикальном «подтягивании» одного или двух
поддеревьев путем манипуляций ссылками на потомков в вышестоящих вершинах, реле-
вантных для восстановления баланса. Среди этих манипуляций такие: подчинение корня
левому поддереву и переподчинение внука, выравнивающее баланс, и подъем на два
уровня внутреннего поддерева, включение в которое привело к несбалансированности. При
этом относительное горизонтальное расположение переставляемых вершин остается без
изменений. Мы просто передергиваем ветки поддеревьев как нитки к куклам-марионеткам,
«не перекрещивая пальцы».

Схема алгоритма включения в сбалансированное дерево такова:
1. поиск элемента в дереве (неудачный!);
2. включение новой вершины и определение результирующего показателя сбалансиро-
ванности;
3. отход по пути поиска с проверкой показателя сбалансированности для каждой про-
ходимой вершины, балансируя в необходимых случаях соответствующие поддеревья.
-----------------------------------------------------------------------------------------------------------------------------------------------

36. Сбалансированные деревья поиска. Удаление

Вспоминая, что исключение из дерева сложнее включения, следовало бы того же ожидать
и от AVL-дерева. Процедура следует схеме включения элемента. Удаление терминальной
или однодетной вершины — задача в одно действие. Двудетные вершины обрабатываются
так же, как и раньше: они заменяются на самую правую вершину ее левого поддерева.
Мы ограничимся лишь иллюстрацией процесса удаления.

Исключение любого элемента из сбалансированного дерева оценивается O(logN)

/*ЗДЕСЬ НУЖЕН РИСУНОК ТОЛЬКО ЧТО РАЗБАЛАНСИРОВАВШЕГОСЯ AVL-ДЕРЕВА из-за удаления вершины*/

-----------------------------------------------------------------------------------------------------------------------------------------------------------

37. Задача поиска. Простые методы поиска в последовательностях и таблицах

Одно из наиболее часто встречающихся в программировании действий — поиск.
Эффективность поиска часто является основным критерием качества различных структур
данных.

К классическим задачам поиска слова в тексте или отыскания данных в базах
данных в последние годы добавились такие актуальные задачи, как поиск в интернете,
антивирусное сканирование программного кода и антиспамовская фильтрация почтовых
сообщений. 

ЛИНЕЙНЫЙ ПОИСК заключается в последовательном просмотре массива как списка с той
же линейной сложностью: O(N). Просмотр выполняется в цикле, условие завершения
которого таково:
• элемент найден: ∃i:(0≤i<N)&(a[i] = x);
• обход массива завершен, но искомый элемент не найден.

Ускорить поиск поможет барьерный элемент, который надо поместить в N + 1-ый
элемент массива, имеющий индекс N :
int a[N+1];
a[N] = x;
i=0;
while(a[i] != x)
    i++;

Здесь мы, как и в случае со списком, перешли от цикла с параметром — дискретным
временем к циклу по сплошному участку массива. Издержки поиска с барьерным эле-
ментом — это дополнительный элемент массива, инструкция присваивания для засылки
барьерного элемента и несколько более сложная интерпретация кода.
Осуществляя линейный поиск, мы предполагали равные шансы отыскания элемента
на любом из N возможных мест. Кроме того, очевидно, что этот метод поиска единственно
возможный для структур данных со строго последовательным доступом, в частности,
основанных на поступательном или вращательном электромеханическом движении маг-
нитного или оптического носителя.

ДВОИЧНЫЙ ПОИСК
Хорошо известно, что поиск данных в упорядоченном множестве с произвольным досту-
пом к элементам более эффективен.
Мы помним, что быстрый поиск данных в дереве был предопределён упорядоченной
структурой дерева и существенным сокращением перебора элементов. При каждом
сравнении отбрасывалась половина из ещё нерассмотренных элементов. В упорядоченных
множествах прямого доступа мы можем добиться такой же эффективности.

Для того, чтобы отбросить при поиске половину элементов, и продолжить поиск
половинным делением, надо выяснить, в какой половине находится искомый элемент.
В силу данного отношения порядка, если выбрать некоторое промежуточное значение
индекса m, то отыскиваемый элемент x либо равен am, либо больше его, либо меньше.

int L, R;
L = 0;
R = N; /* Барьерный индекс > максимального N - 1 . Если R в результате поиска останется равным N, то поиск неудачен */
int m;
while(L < R)
{
    m = (L + R) / 2;/* Деление переменных целочисленного типа дӓeт результат без остатка */
    if (a[m] < x)
    {
        L = m + 1;
    }
    else
    {
        R = m;
    }
}
if((R != N) && (a[R] == x)) /* Если R != барьерному индексу и a_r == x*/
{
    printf("\nNumber %d found, his order in list %d", a[R], R+1);
}
else /* Иначе поиск неудачен */
{
    printf("\nThe number not found in list");
}

Несмотря на сокращение проверок, сложность этого поиска все равно логарифми-
ческая. Другой особенностью этого поиска является позднее обнаружение совпадения
серединных элементов искомых отрезков ввиду отсутствия их проверки на равенство.

Отличие поиска в таблице от поиска в массиве заключается в том, что в таблицах ключ
обычно является составным и имеет регулярную структуру, т. е. сам является массивом,
чаще всего словом или строкой.

Таблица - прямоугольная структура данных. В ней мы по ключам ищем значения, которые за ними прячутся.
Ключи могут быть составными. 
 
Наиболее распостранены следующие представления строк.
1. Как уже это делалось при отображении списков, размер строки явно не указывается.
Сама строка простирается от начала, заданного адресом или указателем, и до конца,
определяемого терминирующим элементом. В качестве ограничителя строк обычно
используют непечатный элемент кода с минимальным порядковым номером char(0),
предшествующий обычным видимым буквам алфавита. Именно так реализованы
строки в Си и в Модуле-2, аналогично их можно запрограммировать в стандартном Паскале

2. Размер строки агрегируется с её телом и хранится в её первом (нулевом) элементе
как сверхкороткое целое. В этом случае легко извлечь длину строки из её структуры
и не тратить ресурсы на подсчёт. Недостатками этого способа являются: ограничение
длины строки мощностью алфавита, усложнение интерпретации строки и возможные
ошибки ввиду полной несовместимости с первым способом.

Далее мы будем отдавать предпочтение первому способу представления строк. Он
позволяет организовать их сравнение и копирование более быстрым барьерным методом.

Особенность поиска по составному ключу
в том, что поиск искомого ключа среди других ключей таблицы в свою очередь требует
последовательных сравнений компонент ключа.

-----------------------------------------------------------------------------------------------------------------------------------------------

38. Алгоритм Кнута-Мориса-Пратта

Данный алгоритм используется для поиска заданной подстроки в строке. В отличие от "наивного" поиска, работающего за O(N*M),
где N - длина строки, а M - длина образца, данный алгоритм работает за O(N+M), что значительно быстрее.

Достоинством КМП-алгоритма является его однопроходность. Это удобно, ведь не нужно возвращаться назад.

Сама идея алгоритма:
В данном методе используется так называемая префикс-функция, которая вычисляется для заданного шаблона(образца).
Каждой букве в образце присваивается некое значение данной префикс-функции.
Разберем пример:
a a b c a a b c c
0 1 0 0 1 2 3 4 0

В данном алгоритме префиксом слова называется любая последовательность его первых букв, длина которой меньше, чем длина слова.
А суффиксом называется любая последовательность его последних букв, длина которой меньше, чем длина слова.

Вычисляя префикс-функцию, мы смотрим, какие равные по длине префиксы и суффиксы совпадают и берем из всех подходящих те, 
длина которых наибольшая, и записываем под данной буквой значение этой длины.

После вычисления префикс функции начинается сам алгоритм.

Заведем два указателя i и j для строки и образца соответственно.
Если str - это строка, t - шаблон, а p - массив с вычисленной префикс функцией, то:   
int i = 0, j = 0;
while(i < n) // n - длина строки
{
    if(str[i] == t[j])
    {
        i++;
        j++;
        if(j == m)
        {
            printf("Detected: i = %d\n", i);
            break;
        }
    }
    else
    {
        if(j > 0)
        {
            j = p[j-1]; //смещаем j на значение преф. функции от j-1 элемента в образце
        }
        else
        {
            i++; // первая буква образца не совпадает с текущей буквой строки
        }
    }
}
-------------------------------------------------------------------------------------------------------------------------------------------------

39.  Алгоритм Бойера-Мура

Алгоритм делится на несколько этапов. 
Первый этап - это вычисление некоторой функции от каждой буквы в образце.
Берем образец и начинаем анализировать его справа налево. Будем искать самое правое вхождение каждой буквы в данный образец и сопоставлять ей расстояние индекса этого вхождения от самой последней буквы.
Например: 
    Д А Н Н Ы Е                З О Р Р О
    5 4 2 2 1 6                4 3 1 1 3
Однако начинать вычисление этой функции надо с предпоследней буквы, так как в случае, если мы не найдем последнюю букву, ей нужно будет присвоить индекс, равный длине всего образца. Если же буква будет найдена, ей, как и другим, будет присвоено значение расстояния самого правого вхождения этой буквы от конца образца.

Д А Н Н Ы Е *     <---- дописываем знак *, обозначая таким образом все оставшиеся буквы, которые не входят в образец 
5 4 2 2 1 6 6

Следующий этап:

Сравнение образца с текущей подстрокой начинаем производить также с его конца, а по самой строке проходимся начиная с левого края.
Самый лучший вариант возможен тогда, когда текущая последняя буква полностью отсутствует в образце. В таком случае необходимо сместиться вправо на значение равное длине образца.
ЕСЛИ НЕСОВПАДЕНИЕ ПРОИСХОДИТ НЕ ДЛЯ ПОСЛЕДНЕГО ЗНАКА, А ДЛЯ ЛЮБОГО ДРУГОГО, ТО
СЛЕДУЕТ БРАТЬ ТЕКУЩИЙ СИМВОЛ ИЗ ОБРАЗЦА И СМЕЩАТЬ САМ ОБРАЗЕЦ НА ЗНАЧЕНИЕ, РАВНОЕ ВЫЧИСЛЕННОМУ НА ПРЕДЫДУЩЕМ ЭТАПЕ РАССТОЯНИЮ.

Если дошли до первого элемента образца и он совпал, значит искомый образец найден.

Данный алгоритм учитывает те буквы, которые просто напросто отсутствуют в образце.
Благодаря этому сложность данного алгоритма в лучшем случае - O(N/M), 
где N - длина строки, в которой происходит поиск, а M - длина образца

Однако легко придумать самый плохой случай для данного алгоритма:
строка: aaaaaa....(N знаков)
образец: baaaaa... (M знаков)

В этом случае сложность алгоритма будет составлять O(N*M)

-------------------------------------------------------------------------------------------------------------------------------------------------

40. Алгоритм Рабина-Карпа

Данный алгоритм применяется для поиска образца в строке. Его идея заключается в следующем:
Для каждой подстроки длины образца в исходной строке будем вычислять многочлен по схеме Горнера.
То есть каждой подстроке будет сопоставлено некоторое число, которое будет отличать ее(подстроку) от других подстрок.
В свою очередь и для образца мы вычислим такое число, чтобы можно было сравнивать подстроки и образец, не перебирая все литеры. 

Однако могут начаться проблемы, связанные со слишком большим значением таких чисел. Поэтому будем брать их по модулю q.
Число q является максимальным простым числом, для которого выполняется условие: число p * q должно помещаться в одно машинное слово, 
где p - десятичное изображение данной подстроки
Так как простое число очень большое, риск коллизии значительно снижается.

Чтобы каждый раз не вычислять значение текущей подстроки заново, воспользуемся следующм методом:

S_(j+1) = 10(S_j − 10^(M−1) * s_j) + s_(j+M)

S_(j+1)=(d(S_j − s_j * h) + s_(j+M)) mod q, h ≡ d^(M−1)  (mod q).

Просто напросто будем исключать значение первой буквы с соответствующего порядка из предыдущего числа, 
умножать полученное число на 10 и прибавлять числовое значение буквы с индексом j+1.
Пересчет в таком случае будет занимать константное время.

В случае, когда числовые значения подстроки и образца совпали, это еще не значит, что образец найден, так как,
хоть вероятность того и мала, может быть такое, что у чисел просто один и тот же остаток от деления на выбранное простое число.
Поэтому необходимо проверить на совпадение каждую литеру, то есть выполнить классическое сравнение данной подстроки с образцом.

Вообще, числовое отображение строки является не чем иным, как процессом ее хеширования. В лучшем случае алгоритм Рабина-Карпа 
работает за O(N+M), а в худшем случае - за O(M(N-M+1)). Многое зависит от функции хеширования, которая будет применяться.
Чем лучше она будет, т.е. чем меньше коллизий встретится на пути, тем эффективнее проявит себя алгоритм.

------------------------------------------------------------------------------------------------------------------------------------------------

41. Таблицы с прямым доступом

Ранее мы рассмотрели вопросы ускорения поиска с помощью упорядоченных таблиц и де-
ревьев поиска, которые дали логарифмическое время доступа. Возможно ли дальнейшее
ускорение доступа? Ведь обращение к каждому элементу данных осуществляется в конце
концов по конкретному физическому адресу, и если мы сможем быстро вычислить этот
адрес по ключу, то фактически мы получим прямой доступ за несколько большее, но
постоянное время. Для этого необходимо построить отображение H ключей K в адреса
A (или в индексы I ):
H : K -> A.

Поместим нашу таблицу в обычный массив и построим преобразование ключей в индексы. 
Напомним, что массив — это эффективная структура данных с доступом за постоянное
время, и для доступа к его элементам уже применяется некоторая расстановочная
функция A = b + (i − 1) · sizeof (T), где b — адрес начала массива, sizeof (T) — размер
компоненты вектора в байтах, а i — индекс компоненты вектора, отсчитываемый от 1, 
как это принято в линейной алгебре. По соображениям эффективной аппаратной
реализации массивы следует индексировать с 0, как это делается в языке Си. Для
многомерного массива эта функция является многочленом, степень которого равна числу
измерений массива, а коэффициенты — суть его размеры по соответствующим индексным
координатам. Естественно, многочлен вычисляется по экономной схеме Горнера. Так, для
матрицы 3 × 4 из восьмибайтных целых функция H имеет вид:
H(i,j)=b+(i·4+j)·sizeof(T), гдеi=0 . . .2, j = 0 . . .3, sizeof(T)=8.

Итак, существует эффективный доступ к элементам массива за постоянное время.
Применим это подход для доступа к элементам с произвольным ключом. Если ключ —
некое слово w из букв a_1 . . . a_m , то мы можем подставить в нашу схему Горнера вместо
индексов элемента i, j , k , . . . числовые коды этих букв ord(a1 ), ord(a2), . . . и, как
все математики, считать задачу в принципе решенной. Однако как программисты мы
вынуждены констатировать, что произведение этих кодов даже для восьмибуквенного
ключа даст нам 16 384 терабайта, что составляет максимальное адресное пространство,
аппаратно поддерживаемое современными процессорами. То есть при лобовом преобразо-
вании ключей множество возможных значений значительно шире множества допустимых
адресов в памяти (индексов массива). С другой стороны, делать такое полное отображение
не имеет смысла, ведь реальные множества ключей значительно ́уже, и требовать
взаимнооднозначного соответствия ключей и адресов излишне. Один из рецептов такого
отображения — сопоставить нескольким ключам один и тот же адрес в надежде на
малую вероятность одновременного появления в таблице ключей, претендующих на этот
адрес. Таким же образом мы отображали целую окрестность точки вещественной оси в ее
конечного рационального представителя.
Если же этот маловероятный случай произошел, и ключ преобразован в уже занятый
адрес, то есть надежда вычислить за постоянное время еще один адрес, куда и переадре-
совать элемент с таким ключом. При поиске в таблице ситуация будет обратной: в случае
неудачи по вычисленному адресу уже находится элемент с другим ключом, поэтому,
как в случае поиска подстроки алгоритмом Рабина-Карпа, необходимо проверять точное
совпадение ключей. Такие ситуации называются коллизиями или конфликтами, а метод
прямой адресации таблиц на основании функции ключа получил название хеширование
(hashing).

------------------------------------------------------------------------------------------------------------------------------------------------

42. Задача сортировки. Классификация и свойства сортировок

Сортировка представляет собой хороший пример задачи, для решения которой существует
множество различных алгоритмов.
Cортировку следует понимать как процесс перестановки заданного множества объ-
ектов в некотором порядке. Цель сортировки — облегчить последующий поиск элемен-
тов в таком отсортированном множестве. Сортировка — это один из универсальных
основополагающих видов обработки данных. Телефонные книги, словари, оглавления
библиотек, прайс-листы — вот примеры отсортированных для поиска множеств хранимых
объектов.
Выбор алгоритма всегда зависит от структуры обрабатываемых данных. В случае
сортировки эта зависимость столь глубока, что соответствующие методы распадаются
на два почти непересекающихся класса — сортировку массивов и сортировку файлов
(последовательностей). Иногда их называют внутренними и внешними сортировками,
поскольку массивы хранятся в основной (оперативной, внутренней) памяти машины с про-
извольным доступом, а файлы обычно размещаются в медленной, но более емкой, дешевой
и долговременной внешней памяти, на электромеханических устройствах, основанных
на поступательном или вращательном движении носителя.

Ключ идентифицирует каждый элемент множества и определяет его итоговое
местоположение в упорядочиваемой последовательности. Для исследования алгоритмов
сортировки существенен только ключ каждого элемента. 

Метод сортировки называется УСТОЙЧИВЫМ (стабильным), если в процессе сортировки
относительное расположение элементов с равными ключами не изменяется.
Метод сортировки называется ЕСТЕСТВЕННЫМ, если в процессе сортировки учитывается
частичная или полная упорядоченность элементов сортируемого множества.

--------------------------------------------------------------------------------------------------------------------------------------------------

43. Сортировка вставкой 

Этот метод широко используется при игре в карты: игрок обычно располагает имеющиеся
карты в левой руке веером в порядке возрастания ранга, а сдаваемая карта вставляется
сообразно ее рангу после последней карты того же ранга. 

Имеется отсортированная и неотсортированная части массива. Берем первый элемент из неотсортированной части массива.
Его необходимо вставить на нужную позицию в отсортированной части массива, поэтому ищем позицию для вставки.
После этого раздвигаем отсортированную часть массива и вставляем новый элемент на нужное место. 
Для начальной ситуации один первый элемент является отсортированной частью массива.

Оценим сложность данной сортировки.
Для поиска места для вставки очередного элемента нужно потратить N операций. Однако этот этап может быть улучшен применением 
двоичного поиска, так как поиск мы осуществляем в уже отсортированной части массива.
Следующим этапом является сдвиг всех элементов, которые больше нового, вправо. Эта операция очень дорогая - стоит O(N).
А выбираем каждый новый элемент мы тоже за O(N).
Поэтому сложность данной сортировки квадратичная - O(N^2).
Сортировка применяется только на массивах маленьких размеров, на больших размерах применять крайне НЕ рекомендуется!

Данная сортировка является естественной, устойчивой, но НЕ является обменной.

--------------------------------------------------------------------------------------------------------------------------------------------------

44. Сортировка выборкой

Так же, как и в алгоритме сортировки вставкой, имеется уже отсортированная и еще не отсортированная части массива.

Алгоритм основан на простой идее:
• в неотсортированной части массива отыскивается элемент с наименьшим ключом;
• он меняется местами с первым элементом a1 неотсортированной части массива;
• процесс повторяется для оставшихся n − 1-ого, n−2-х, . . . элементов до тех пор, пока
не останется один, самый большой элемент.

Метод выборки в некоторым смысле противоположен методу вставки. При прямой
вставке на каждом шаге рассматривается только один очередной элемент исходной после-
довательности и все элементы готовой последовательности, среди которых отыскивается
место вставки. При прямом выборе для поиска одного элемента с наименьшим ключом
просматриваются все элементы исходной последовательности, и найденный минимальный
элемент помещается в выходную последовательность как очередной элемент. Поскольку
сортировка выборкой также выполняется на месте и обмен возможен ввиду прямого
доступа к элементам массива, то вместо удаления минимального элемента из входной
последовательности на его место помещается очередной рассматриваемый элемент ai,
который будет впоследствие обязательно рассмотрен среди оставшихся элементов.

Сортировка выборкой является квадратичной сортировкой, так как сложность поиска минимального элемента на каждом шаге стоит O(N), 
таких шагов в свою очередь N. 
Данная сортировка является естественной, НЕ является обменной, является устойчивой.

Данный метод предпочтительнее простой вставки. Однако если массив изначально упорядочен или почти упорядочен, вставка будет
работать чуть быстрее.

-------------------------------------------------------------------------------------------------------------------------------------------------

45. Обменные сортировки

    "Смешать, но не взбалтывать" 
                    Джеймс Бонд

В данном разделе мы опишем простой метод сортировки, в котором обмен местами
двух элементов производится не с целью вставки или выборки, а непосредственно для
упорядочения. Так называемый алгоритм прямого обмена, основывается на сравнении
и перестановке пар соседних элементов до тех пор, пока таким образом не будут
упорядочены все элементы.

Как и при сортировке выборкой мы осуществляем проходы по массиву, постепенно
сдвигая наименьший элемент оставшейся последовательности к левому краю массива.
Если мы откажемся от горизонтальной ориентации сортируемых последовательностей
в пользу вертикальной, то упорядочение этим методом можно интерпретировать как
всплытие (погружение) пузырьков в чане с водой (в стеклянной колонне с пивом) сообраз-
но их весу, точнее, плотности. Этот гидрогазодинамический смысл обменной сортировки
и дал ей более популярное название пузырьковой сортировки.

Сразу внесем в нашу переборную идею такое улучшение: поскольку легчайший пузырек
всплывает наверх всего за один проход, то при последущих просмотрах можно исключать
из рассмотрения по одному такому элементу и тем самым несколько ускорить пузырько-
вую сортировку. Вспомните сортировку выборкой, когда минимум отыскивался не во всей
последовательности, а в ее нерассмотренном остатке!

Существует так называемая ШЕЙКЕРНАЯ СОРТИРОВКА.
Это улучшенная версия сортировки пузырьком.
Пройдя с левой стороны вправо, самый большой пузырек окажется на последней позиции массива.
Нет смысла его затрагивать при последующиех проходах. 
Важная особенность - теперь мы не будем всегда начинать обменный проход сначала, а пойдем с конца.
Дойдя до начала, по пути обменивая элементы, если правый оказался меньше левого, получим на первой позиции 
самый маленький элемент во всем массиве. Его тоже теперь можно не рассматривать.
И теперь пойдем обратно - вправо. Таким образом мы постепенно выталкиваем вправо самый большой из оставшихся, 
а влево - самый маленький. Из-за характера таких проходов данная сортировка и была названа шейкерной, так как напоминает 
взбалтывание коктейля(другое название сортировки - челночная, так как напоминает ход челнока)

Несмотря на все усовершенствования, пузырьковая сортировка всё так же остаётся квадратичной.

--------------------------------------------------------------------------------------------------------------------------------------------------

46. Сортировка Шелла

Сортировка Шелла является улучшенной версией сортировки вставкой.
Было предложено выделять в сортируемой последовательности периодические
подпоследовательности регулярного шага, в каждой из которых отдельно выполняется
обычная (или двоичная) сортировка вставкой. Эти подпоследовательности пронизыва-
ют крупными стежками всю сортируемую последовательность и, по построению, дают
большие перемещения элементов. Ввиду регулярного шага (периода) и прямого доступа
к элементам массива (индексированного, конечно же, целым типом) прохождение этих
подпоследовательностей реализуется циклом с параметром for.

После каждого прохода шаг подпоследовательностей уменьшается и сортировка повторяется с новыми прыжками,
причем переход к меньшему шагу не только не требует затрат на организацию новых
подпоследовательностей, но и не ухудшает сортированность упорядочиваемого массива.
Последней выполняется сортировка с шагом 1, подчищающая огрехи предыдущих проходов.

При кратном уменьшении шага,
например, 8 4 2 1 мы в конце концов получим две автономные подпоследовательности
и на завершающем проходе нам придётся «много вставлять». Избежать этого можно, по
рецепту Д. Кнута, используя последовательность
1 4 13 40 121 364 1093 3280 9841...3n+1 ....

Эта последовательность приводит к хорошему «перемешиванию» организуемых под-
последовательностей и сводит к минимуму их изолированность, и на последней стадии
сериализации вставка будет идти почти без ресурсоемких сдвигов. Наверное, сортировка
Шелла может базироваться и на других простых методах, но метод вставки из них
не только относительно быстрый, но и обладает позитивной реакцией на частичную
упорядоченность последовательности, которая имеет место в результате предыдущих
проходов.

Сортировка Шелла НЕ является устойчивой, является естественной и НЕ является обменной, поскольку основана на сортировке вставкой.
Сложность данной сортировки оценить крайне трудно, тем более, что она варьируется в зависимости от выбранной последовательности шагов.

--------------------------------------------------------------------------------------------------------------------------------------------------

47. Турнирная сортировка

Эта сортировка эксплуатирует естественность сортировки вставкой.

А давайте усовершенствуем сортировку выборкой!
Откуда берутся лишние сравнения в сортировке выборкой?
А оттого, что мы многократно пытаемся выбрать минимальный элемент, поиск то линейный 

Каждый раз мы просеиваем уже в некотором роде просеянные элементы.

Массив, в котором мы работаем, не приспособлен для сокращения перебора

Надо бы сохранять, что какой-то элемент является чемпионом!
Для этого подходит структура дерева

Надо хранить победителей предыдущих туров и не делать лишних сравнений

Каждые два элемента массива играют в поддавки. Меньший уходит наверх
Таким образом в корне данного дерева получится самый минимальный элемент.

Мы, конечно, по памяти проигрываем, но зато избегаем лишних сравнений.
Пространственная сложность такой сортировки за счет дерева двойная.

Эта сортировка быстрее, чем Шелл
Но памяти требует больше.

Дерево выбора представляет собой на самом деле приоритетную очередь!!!
Почему мы выигрываем? Дерево сохраняет историю!

Общая оценка сортировки остается линеарифмической(NlogN)(мы победили Шелла)

Критика турнирного метода: используется двойная память!!!

Как с этим бороться?
Это турнирное дерево легко отображается на массив.


--------------------------------------------------------------------------------------------------------------------------------------------------


48. Пирамидальная сортировка(сортировка Флойда)

Существует модификация сортировки выборкой, оставляющая после каждого прохода
гораздо больше порядковой информации, чем просто минимальное значение. 

Для данного метода сортировки нам потребуется такая структура данных, как куча.
Это двоичное дерево, значение корня которого не больше, либо не меньше значений корней левого и правого поддеревьев.
Куча также определяется рекурсивно, поэтому данное условие распространяется на все корни всех поддеревьев.

Процесс сортировки состоит из нескольких частей:
1)Построение исходного дерева из элементов. Сначала массив условно превращается в дерево. Будем манипулировать элементами, как поддеревьями, 
используя следующую индексацию: если индекс корня равен i, то индекс его левого ребенка равен 2*i+1, индекс правого ребенка равен 2*i+2, 
при этом 2*i+2 < n, где n - число элементов в исходном массиве.
2)Теперь необходимо сделать из обычного двоичного дерева кучу. Начнем так называемое просеивание. Если какой-то из детей больше, 
чем его родитель, необходимо поменять их местами. Просеивание мы будем начинать не с самого нижнего уровня, так как листья
и так являются кучами, а на уровень выше, постепенно пробираясь наверх.
3)Теперь в корне находится самый большой элемент массива. Его индекс в исходном массиве на данный момент равен нулю.
Поменяем его местами с последним элементом. Теперь он стоит на правильной позиции для отсортированного массива.
Для последующих просеиваний этот элемент мы учитывать не будем. Теперь последний элемент массива имеет индекс k-1, где k - индекс предыдущего последнего элемента.
4)Будем просеивать кучу заново, так как после предыдущего обмена в корне находится другой элемент. 
Важный момент заключается в том, что мы не будем брать в расчет те элементы, которые были перемещены в конец на предыдущем шаге.
5)Повторять п.4-5, пока условное дерево не будет состоять из одного элемента.

Данная сортировка имеет сложность O(N*logN) и в лучшем, и в худшем случаях. Дополнительной памяти она практически не требует.
Сортировка НЕ является устойчивой, НЕ является обменной и НЕ является естественной.
При этом у пирамидальной сортировки нет ни вырожденных, ни лучших случаев. Любой массив будет обработан на приличной скорости, но при этом не будет ни деградации, ни рекордов.
Сортировка кучей в среднем работает несколько медленнее чем быстрая сортировка. Но для quicksort можно подобрать массив-убийцу, на котором компьютер зависнет, а вот для heapsort — нет.

Поведение алгоритма сортировки называется естественным, если время сортировки минимально 
для уже упорядоченного списка элементов, увеличивается по мере возрастания степени неупорядоченности списка 
и максимально, когда элементы списка расположены в обратном порядке.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
49. Гладкая сортировка

Данный алгоритм работает за O(NlogN) в худшем случае и за O(N) в лучшем случае. Этот лучший случай является почти отсортированной последовательностью.
Подобно пирамидальной гладкая сортировка обрабатывает массив в два прохода.
Результатом первого прохода является построение из элементов массива нескольких частично упорядоченных деревьев.

Введем в рассмотрение последовательность чисел Леонардо: 
L_0 = L_1, 
L_(K+2) = L_(K+1) + L_K + 1
Похоже на числа Фиббоначчи
Любое натуральное число может быть представлено в леонардовой системе счисления.

Здесь также будут применены кучи. Только теперь они будут называться леонардовыми.
В корне также будет максимальное значение.
Мы будем идти по массиву и пытаться построить леонардову кучу. Это можно сделать,
если собралось нужное число элементов. То есть из L_k-1 и L_k можно построить
кучу с количеством элементов L_k+1. 
То есть мы можем построить леонардову кучу только в том случае, когда предыдущие кучи представялют собой соседние числа Леонардо.

После создания очередной леонардовой кучи необходимо выполнить просеивание.
То есть самый большой элемент должен обязательно попасть в корень дерева.

Итак, корень каждой кучи это последний элемент соответствующего подмассива(количество "подмассивов" определяется числом леонардовых куч).

На втором же этапе мы разбираем кучи. Ищем максимум среди элементов всех куч.
Так как каждая куча была просеяна, максимум находится в корне. То есть нам нужно просто найти максимум среди предыдущих корней.

После этого меняем его местами с элементом, который находится в корне последней кучи.
Просеиваем кучу, корнем которой был максимальный элемент, которая, возможно, потеряла свои свойства, когда в корне оказался другой, меньший, элемент. 

Теперь самый максимальный элемент находится в конце массива.
Разбираем последнюю леонардову кучу на две кучи и максимальный элемент из рассмотрения исключаем. 

Таким образом проделываем те же самые действия для всех оставшихся леонардовых куч.

Сортировка является естественной, НЕ является устойчивой, НЕ является обменной.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
50. Быстрая сортировка

Суть сортировки заключается в следующем: 
Берем некий зерновой элемент. Рассматриваем все элементы с такой точки зрения:
все элементы, которые меньше зерного элемента идут в один массив, а все те, которые больше либо равны, - в другой массив.
В лучшем случае оба подмассива должны иметь примерно одинаковую длину, поэтому если на каждом шаге для каждого подмассива 
разделять элементы на две примерно равные части, мы получим заветную сложность разбиения O(logN).
Будем измельчать подмассивы до тех пор, пока они не станут отсортированными, а таковыми являются только массивы единичной длины.

После этого необходимо "склеить" отсортированные части подмассива. Первыми будут те, что меньше последнего опорного элемента, 
а потом к ним присоединятся те, что больше последнего опорного элемента.

Данный алгоритм довольно легко программируется с использованием рекурсии. Базой рекурсии является массив длины, равной 1.

Однако в случае выбора плохого опорного элемента, сложность разбиения может выродиться в O(N). Это, например, случай, 
когда опорный элемент всегда первый в текущем подмассиве.

Есть разные способы выбора зернового элемента. Один из наиболее эффективных - медиана трёх элементов: первого, среднего, последнего.
Либо же выбор случайного элемента.

void QuickSort(int a[])
{
/* Быстрая сортировка Хоара */
/* Основной принцип: производим разделение массива в границах [L..R] так, чтобы левая половина содержала элементы 
меньшие некоторого x, правая - большие */
    void RecSort(int L, int R)
    {
        int w, x;
        int i = L, j = R;
        x = a[(L + R) / 2]; /* выбираем зерно - средний элемент */
        /* Разделение массива */
        do
        {
        /* Два совмещенных просмотра во встречных направлениях (i++, j--
        !!!) */
            while(a[i] < x)
            {
                i++;
            }
            while(a[j] > x)
            {
                j--;
            }
            if(i<=j)
            {
                w = a[i];
                a[i] = a[j];
                a[j] = w;
                i++; j--;
            }
        } while(i<=j);
        if(j > L)
        {
            RecSort(L, j); /* Сортировка левой половины перепоручается вновь а
            ктивируемому экземпляру этой же процедуры */
        }
        if(i < R)
        {
            RecSort(i, R); /* Сортировка правой половины перепоручается вновь
            активируемому экземпляру этой же процедуры */
        }
    } /* RecSort */
    RecSort(0, n -1); /* Sort */
}  


Если, например, говорить о нерекурсивном алгоритме данной сортировки, то в таком случае будет использоваться стек.
То есть мы ручками будем моделировать стек рекурсивных вызовов. В качестве самого оптимального решения такого плана
стоит отметить хранение лишь границ текущего подмассива, используя которые можно с легкостью оперировать лишь исходным цельным массивом.

Сортировка является действительно быстрой O(NlogN) в среднем. Разумеется, для определнных массивов сложность может выродиться в O(N^2)
Однако также и на некоторых массивах сортировка может иметь сложность O(N). 

Разительное отличие от пирамидальной сортировки, которая на любом массиве работает за O(NlogN).

Сортировка Хоара НЕ является естественной, НЕ является устойчивой и НЕ является обменной.

ВАЖНЫЙ МОМЕНТ: почему сортировка Хоара используется намного чаще по сравнению с гладкой сортировкой? Казалось бы, 
сложность плавной сортировки - O(N) на почти отсортированных массивах, ну а в худшем случае она показывает результаты O(NlogN), 
то время, как худший случай для quick sort может обойтись ей в O(N^2). 
По факту же почти или полностью упорядоченные последовательности встречаются крайне редко. Также стоит отметить, что константа 
в оценке сложности гладкой сортировки довольно увесистая, так как число сравнений и промежуточных вычислений велико, 
поэтому она и проигрывает быстрой сортировке, которая в среднем работает чётко быстро за O(NlogN). 

------------------------------------------------------------------------------------------------------------------------------------------------------------

51. Сортировка слиянием

Характерным методом внешней сортировки является метод слияния. Под слиянием понимается подобное слиянию двух рек объединение двух или
более входных последовательностей в одну-единственную упорядоченную выходную по-
следовательность с помощью повторяющегося выбора из доступных в данный момент
резидентных (буферных) элементов.
То есть слияние представляет собой выбор из буферных переменных каждой подпоследовательности той переменной, которая должна стоять раньше.

Сортировка слиянием происходит в условые три этапа:
1)Разделение сортируемой последовательности на две половины  
2)Сортировка каждой из подпоследовательностей
3)Слияние уже отсортированных подпоследовательностей

Лишь только массив длиной не больше 1 считается отсортированным.
Данный алгоритм довольно просто запрограммировать, используя рекурсию.

/*ЗДЕСЬ НАДО НАПИСАТЬ ПРИМЕР СЛИЯНИЯ И В ЦЕЛОМ СОРТИРОВКИ СЛИЯНИЕМ*/

Нетрудно оценить, сколько стоит разбиение последовательности пополам на каждом шаге - O(logN), где N длина исходной последовательности.

Самая дорогая операция в данном алгоритме - это слияние. Вот оно уже стоит O(N).

Итоговая сложность O(NlogN)
Сортировка НЕ является естественной, может являться устойчивой(взависимости от слияния), НЕ является обменной.
----------------------------------------------------------------------------------------------------------------------------------------------------------

52. Сортировка естественным слиянием

Сортировка естественным слиянием является еще более быстрой по сравнению с обычным слиянием. В основе этого алгоритма
предположение о том, что в последовательности уже могут быть упорядоченные отрезки.
Положим, что у нас есть 4 ленты:
1:
2:
3:
4:

На первой ленте вначале находится исходная последовательность. Далее переносим элементы с первой ленты на третью, пока выполняется условие, 
что каждый текущий элемент не меньше предыдущего. Иначе начинаем переносить элементы с первой ленты на четвертую, тоже пока выполняется это условие.
То есть переключаемся(совершаем инверсию) на 3-ю или 4-ю ленту в том случае, если условие для текущей ленты не выполнено.

После этого необходимо произвести слияние 3-ей и 4-ой лент. Результат записываем на первую ленту, запоминая какой элемент был последним.
В случае, когда буферная переменная одной из двух лент(либо 3-ей либо 4-ой) будет меньше, чем текущий последний элемент на 1-ой ленте,
помещаем эту буферную переменную на 2-ую ленту. Далее помещаем результаты слияния 3-й и 4-й лент, пока выполняется это условие.
Когда оно наршится, снова начинаем записывать на 1-ю ленту. 

Если после слияния вторая лента пуста, конец алгоритма - сортировка завершена.
Иначе результат слияния 1-й и второй лент записываем на ленты 3 и 4.
Если у нас только 3-я лента заполнена, то конец алгоритма, иначе повторить процедуру заново.

Отзывчивость естественного слияния на наличие упорядоченных отрезков в сортиру-
емой последовательности — не единственное ее достоинство. Обычное слияние в случае
любого (упорядоченного, почти упорядоченного или совершенно неупорядоченного) файла
выполняет строго n · ⌈log2 n⌉. Сортировка естественным слиянием работает так же плохо
только в худшем случае обратно упорядоченного файла. В случае упорядоченного файла
естественному слиянию необходимо пройти по файлу только один раз, в то время как
обычному опять необходимо n · ⌈log2 n⌉ операций.То есть обычное слияние даже в случае
почти упорядоченных последовательностей трудоголически выполняет отмеренное число
операций, совершенно не используя уже имеющийся частичный порядок.

-------------------------------------------------------------------------------------------------------------------------------------------------------------

53. Анализ методов внутренней сортировки

Рассмотренные нами сортировки можно разделить на две категории:
1) Прямые, наивные, примитивные сортировки, сложность которых O(N^2)
2) Улучшенные линеарифмические сортировки, которые работают за O(NlogN)

Недостатком, например, быстрой сортировки является низкая производительность при небольших n, 
но этим грешат все усовершенствованные методы. Для обработки случаев
малых n в усовершенствованные сортировки включают один из простых методов.

Стоит отметить, что, например, чаще всего используется именно сортировка Хоара, так как оставляет позади практически всех своих конкурентов.
Если сравнивать ее с пирамидальной сортировкой, то быстрая сортировка выигрывает у пирамидальной, если выбрать правильное разбиение.

Почему сортировка Хоара используется намного чаще по сравнению с гладкой сортировкой? Казалось бы, 
сложность плавной сортировки - O(N) на почти отсортированных массивах, ну а в худшем случае она показывает результаты O(NlogN), 
то время, как худший случай для quick sort может обойтись ей в O(N^2). 
По факту же почти или полностью упорядоченные последовательности встречаются крайне редко. Также стоит отметить, что константа 
в оценке сложности гладкой сортировки довольно увесистая, так как число сравнений и промежуточных вычислений велико, 
поэтому она и проигрывает быстрой сортировке, которая в среднем работает чётко и быстро за O(NlogN). 


Среди всех квадратичных сортировок самой привлекательной(если квадратичная сортировка вообще может быть привлекательной) 
является сортировка вставкой, так как она является естественной и устойчивой, а также на упорядоченной последовательности рабоает за O(N).

Например, в большинстве реализаций std::sort() применяются целые комбинации сортировок. Там основное требование состоит в том, чтобы
средняя сложность была O(NlogN), а о гарантии устойчивости речи не идет. Поэтому на больших массивах как правило применяется quicksort, 
а на маленьких сортировка вставкой.

--------------------------------------------------------------------------------------------------------------------------------------------------------------

54. Анализ методов внешней сортировки

--------------------------------------------------------------------------------------------------------------------------------------------------------------

55. Процедурное программирование

Вообще, раньше была известна лишь пара простых технологий программирования.
1)Структурное программирование
Это нисходящая разработка структуры программы, программирование с ограниченным набором конструкций.
2)Процедурное программирование
Это широкое применение процедур и функций

Процедурное программирование основано на широком использовании процедур и функций. 
Набор процедур и функций может быть использован для реализации нового типа данных, который не поддерживается аппаратурой и системой программирования.
Такие типы данных называются абстрактными.

Процедурное программирование позволяет оперировать крупными прикладными понятиями, укрывая детали реализации в телах структур.

Именно абстрактные типы данных позволяют писать программы культурно.

В Паскале, например, есть хорошие структурные элементы, однако из нельзя использовать во внешнем виде, что является большим недостатком.
Язык Си имеет более товарный вид.
------------------------------------------------------------------------------------------------------------------------------------------------------------

56. Модульное программирование

Появляется новая структура данных - модуль. Модуль содержит всё, что нужно для абстрактных типов данных.
Модульное программирование рассчитано на объединение всех структур и процедур для хранения в товарном виде.

То есть например, модуль для такого типа данных как очередь будет состоять из реализации процедур, функций, а главное,
из пользовательского интерфейса, то есть задача модуля - это сделать так, чтобы программист, который использует данный модуль
не задумывался о том, как именно устроена внутреняя кухня. 

Модуль представляет собой программную единицу, изолированную от объектов других программ.    
Он как бы заключен во внутреннюю оболочку, предохраняющую внутренние объекты модуля от нежелательного доступа извне.
Интерфейсом модуля называются те самые разрывы в оболочке модуля, благодаря которым можно получить к нему доступ.

Например, при создании любой программы лучше всего иметь несколько модулей, каждый из которых отвечает за выполнение своей 
конкретной задачи.
Рассмотрим пример:
Нам нужно написать программу на языке Си, которая делает реверс очереди элементов типа double.
Всё, что нам потребуется для выполнения этой задачи, - это модуль queue.c, его интерфейс queue.h, а также сам main.c, в котором
будут выполняться необходимые действия для решения задачи.
Мы будем пользоваться только стандартными функциями из интерфейса очереди. То есть чтобы сделать реверс очереди, воспользуемся
рекурсией:

#include "queue.h"

void queue_reverse(queue *q)
{
    if(q->size < 1)
    {   
        return;
    }
    double cur_elem = queue_first(q);
    queue_pop(q);
    queue_reverse(q);
    queue_push(q, cur_elem);
}

Таким образом мы воспользовались лишь интерфейсом модуля, не думая о том, что именно находится под капотом всех используемых функций.

-----------------------------------------------------------------------------------------------------------------------------------------------------------

57. Абстракции в ЯП

В данном pазделе мы рассмотрим различные виды абстракций и общие принципы
применения их в программах. Наиболее существенным достижением в этой области
является на сегодняшний день развитие языков высокого уровня. Имея дело непосред-
ственно с конструкциями языка высокого уровня, а не с различными наборами машинных
инструкций, в которые данные конструкции могут быть транслированы, программист
существенно упрощает свой труд.

Типы абстрагируются от ЯП. Типы это уровень функциональной спецификации. 
Переменная - это именованная абстрацкция конкретного значения.

Подвал - это железо целевой машины. Над ним - всё остальное.
При абстрактном подходе мы берем главное, а неглавное отбрасываем. 

Ниже абстрактных типов данных опускаться нельзя!

Существуют 2 метода абстракции:
1) Параметризационный (позволяет просто описывать универсальные вычисления и просто реализуется в ЯП)
2) Спецификационный метод (нисходящий метод, при котором мы заменяем процедуру ее заголовком)

При спецификационном методе сначала появляются заголовки и только лишь потом сами программы.
Это позволяет бороться со сложностью программ.
Абстракция через спецификацию позволяет нам абстрагироваться от процесса вычисле-
ний, описанных в теле процедуры, до уровня знания лишь того, что данная процедура
должна в итоге реализовать. Это достигается путем задания для каждой процедуры
спецификации, описывающей эффект ее работы, после чего смысл обращения к данной
процедуре становится ясным через анализ этой спецификации, а не самого тела процеду-
ры.

Виды абстракций:
1) Процедуры - это абстракция 
2) Абстракция типов данных
3) Абстрация через итерацию

-------------------------------------------------------------------------------------------------------------------------------------------------------------

58. Абстрактные типы данных

АТД — это, по существу, определение некоторого понятия в виде класса (одного или более) обьектов
с некоторыми свойствами и операциями.

Абстрактный тип данных - это тип данных, реализованный программистом, не реализванный аппаратно в языке.

Абстрактные типы данных позволяют культурно писать программы.
В абстракции мы берем самое главное. 
Вот типы данных, реализованные в аппаратуре НЕ являются абстрактными!

В самой развитой форме АТД определяется через следующие 4 части:
1) внешность(интерфейс), которая содержит имя определяемого типа, имена операций с указанием типов аргументов и значений.
2) абстрактное описание операций и объектов средствами языка спецификаций
3) конкретное(логическое) описание этих операций на языке программирования
4) описание связи между пунктами 2 и 3

-----------------------------------------------------------------------------------------------------------------------------------------------------------

59. Адресный тип данных

Родовой тип данных позволяет обходить критерий строгой типизации.

Ослабляя ограничения строго типизированных языков, можно
ввести родовой тип данных word, не предполагающий какого-либо особенного использо-
вания памяти, выделяемой для его обьектов. Для типа word определены лишь операция
присваивания и отношение равенства. Также, как и тип множество, тип word является
внутримашинным, нетекстовым, непечатным. По этой причине в этом типе нет констант,
изображающих конкретные значения.

Основное применение типа word связано с ослаблением контроля типов при передаче
параметров. Любой формальный параметр типа word считается совместимым с любым
фактическим параметром, занимающим ровно одно слово в памяти ЭВМ. В обычном
употреблении тип word чужд другим типам, что уменьшает потенциальную опасность
его применения и локализует места его использования.

Другой, более универсальный способ ослабления т́ипового контроля, основан на
применении бестиповых, родовых указателей. Фактически тип родового указателя вводит в обиход
языка высокого уровня адреса соответствующей ЭВМ, единообразно ссылающиеся на
данные любых типов, размещенные в ячейках ее памяти. Поэтому он и получил название
адресного.

Адресный тип имеет множеством значений диапазон допустимых адресов ЭВМ, быть
может суженный до сегмента памяти процесса в мультипрограммных системах с защитой
памяти. Обьекты адресного типа совместимы по присваиванию и сравнению с любыми
ссылочными переменными, а формальные параметры — с любыми ссылочными фактиче-
скими. Кроме того, адресный тип естественно совместим с целым и к нему применимы
арифметические операции, что открывает набор гибких, но весьма
опасных средств свойственной языку Си адресной арифметики. Адресный тип полностью
устраняет контроль типов, выполняемый компилятором, и его следует употреблять только
для разработки родовых модулей низкого уровня.

----------------------------------------------------------------------------------------------------------------------------------------------------------

60. Реализация полиморфизма с помощью адресного типа.

Параметризованные или полиморфные типы — это один из аспектов общего понятия
полиморфизма (многоликости вообще и многотиповости в частности). Понятие поли-
морфной операции, т. е. операции, у которой хотя бы один аргумент допускает значения не
одного, а нескольких типов, встречается почти в любом языке программирования, начиная
с Фортрана, где операция + может применяться как к вещественным значениям, так
и к целым.

Полиморфная очередь может содержать объекты разных типов: TCircle (окружность),
TTriangle (треугольник), TExecutable (выполняемый объект, вызывающий процедуру
саморисования).

Абстрактный указатель должен иметь размер адреса конкретной архитектуры. На-
пример, возможно использование указателя (char ↑, integer ↑), в этом случае размер
определяется автоматически; или использование типа соответствующего размера:

-------------------------------------------------------------------------------------------------------------------------------------------------

61. Процедурный тип данных

Процедурный тип является еще одним способом реализации родовых модулей. Процедурный тип представляет собой класс типов.
Константами процедурного типа являются имена глобально определенных процедур с идентичной спецификацией, включая и тип
результата функций.

Процедурный тип есть своеобразный вариант перечислимого типа.

В конечном итоге, чтобы вызвать процедуру, надо знать ее адрес, роль которого может играть ссылка на процедуру.

Процедурный тип также позволяет организовать полиморфизм. 
-------------------------------------------------------------------------------------------------------------------------------------------------

62. Реализация полиморфизма с помощью процедурного типа


-------------------------------------------------------------------------------------------------------------------------------------------------

63. Объектный тип данных: комбинированные программно-информационные объекты








 
















